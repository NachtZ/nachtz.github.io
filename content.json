[{"title":"数据结构与算法","date":"2017-03-01T05:19:02.000Z","path":"2017/03/01/data_struct_and_ag/","text":"整理和自己总结的部分数据结构和算法。 数据结构队列特点是FIFO。是一种常见的数据结构。可用链表和数组实现。出队时，链表只需要给出链头并将链头重新指向即可，而数组则需要进行一次全数组移动的操作。入队时，链表需要遍历一遍链表，数组则不需要。扩容时，链表是需要遍历一次，而数组需要进行一次拷贝。 树树的子树还是树；度：节点的子树个数；树的度：树中任意节点的度的最大值；兄弟：两节点的parent相同；层：根在第一层，以此类推；高度：叶子节点的高度为1，根节点高度最高；有序树：树中各个节点是有次序的；森林：多个树组成； 二叉树二叉树的数组存储下标公式：第i个节点的左右子节点是2i+1, 2i+2满二叉树的深度为k，节点数是2的k次方-1先序遍历：先访问根节点，再访问左节点，再访问右节点中序遍历：左-&gt;根-&gt;右后序遍历：左-&gt;右-&gt;根中序遍历+另外一种遍历可以还原一棵二叉树。 二叉查找树： 左子树的所有节点值都小于根节点值，右子树所有节点值都大于根节点值。 左右子树也为二叉查找树。 所有节点值都不重复。 先序遍历是递增序，后序是递减序。 插入和删除操作。 红黑树 (有点看不懂,先放着)某blog一种平衡二叉查找树。C++ stl 中set, multiset, map , multimap(muti允许内部有重复元素)用了红黑树。红黑树是每个节点都带有颜色属性的二叉查找树，颜色或红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求: 节点是红色或黑色。 根节点是黑色。3 每个叶节点（NIL节点，空节点）是黑色的。4 每个红色节点的两个子节点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色节点) 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。 关键性质: 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。 旋转旋转是为了让失去平衡的红黑树（比如插删操作后，左右子树的高度不一致了。）重新恢复平衡。如图： 左旋，如图所示（左-&gt;右），以x-&gt;y之间的链为“支轴”进行， 使y成为该新子树的根，x成为y的左孩子，而y的左孩子则成为x的右孩子。 重新着色旋转后红黑色颜色特性被破坏了。需要重新着色。 堆某blog也叫优先队列，是完全二叉树。大顶堆（小顶堆）是父节点大于（小于）两个子节点的值，且两个子节点也都是一个大顶堆（小顶堆）。堆的数组表示：下标从1开始。对一个节点t，他的父节点为t/2，左孩子节点是2t，右孩子节点2t+1.保持堆的性质（heapfy）：左右子树都必须已经是堆(这里，只有一个节点的树显然是堆)。将root 与left, right比较，最大的值与root交换，比如是right，然后递归调整右子树。数组转堆：数组长度为n，从堆的最后一个非叶子节点n/2的地方开始，往前进行heapfy操作。123456void BuildHeap(int A[],) &#123; int i; for(i = HEAP_SIZE(A)/2; i&gt;=1; i--) Heapify(A, i); &#125; 优先队列（priority queue）优先队列是一种基于堆实现的数据结构。其特性是队列中的元素是按照从大到小排列的。 pop操作：获取队列中的最大值 步骤有三步，时间复杂度为o(lg n)： 从堆中取堆顶元素，对应的是堆底层数据存储结构数组A[1]（注意，A[0]是不用留空的。） 将数组A最后一个元素A[n]放在A[1]的位置，同时将数组长度置为n-1. 对数组从上往下往下进行heapfy操作。 push 操作：往队列中加入一个数。步骤有两步，时间复杂度为o(lg n): 在数组A尾部放入这个树。 对该数组至下往上进行heapfy操作。12345678910void Insert(int A[], int i) &#123; //i为插入的值 int n=++HEAP_SIZE(A); A[n] = -99999;//小无穷 int p = n; while(p &gt;1 &amp;&amp; A[PARENT(p)] &lt; i) &#123; A[p] = A[PARENT(p)]; p = PARENT(p); &#125; A[p]=i; &#125; 栈某文库 FILO。懒得打字了。线性表的储存罢了。对栈的操作，感觉更像是一种特殊的约定。他们的操作更像是在线性的数组上认为的添加限制。即加入时只能加到数组头，移出时只能移除数组尾部。 另，计算机的堆区和栈区堆区和栈区实际上不属于数据结构与算法的范畴了，应该是操作系统的部分。但是名字一样在这也补一个。懒得提炼直接复制了。某blog一、预备知识—程序的内存分配一个由c/C++编译的程序占用的内存分为以下几个部分1、栈区（stack）— 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。其操作方式类似于数据结构中的栈。2、堆区（heap） — 一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。注意它与数据结构中的堆是两回事，分配方式倒是类似于链表，呵呵。3、全局区（静态区）（static）—，全局变量和静态变量的存储是放在一块的，初始化的全局变量和静态变量在一块区域， 未初始化的全局变量和未初始化的静态变量在相邻的另一块区域。 - 程序结束后有系统释放4、文字常量区—常量字符串就是放在这里的。 程序结束后由系统释放5、程序代码区—存放函数体的二进制代码。 二、堆和栈的理论知识2.1申请方式stack:由系统自动分配。 例如，声明在函数中一个局部变量 int b; 系统自动在栈中为b开辟空间heap:需要程序员自己申请，并指明大小，在c中malloc函数如p1 = (char )malloc(10);在C++中用new运算符如p2 = (char )malloc(10);但是注意p1、p2本身是在栈中的。 2.2申请后系统的响应栈：只要栈的剩余空间大于所申请空间，系统将为程序提供内存，否则将报异常提示栈溢出。堆：首先应该知道操作系统有一个记录空闲内存地址的链表，当系统收到程序的申请时，会遍历该链表，寻找第一个空间大于所申请空间的堆结点，然后将该结点从空闲结点链表中删除，并将该结点的空间分配给程序，另外，对于大多数系统，会在这块内存空间中的首地址处记录本次分配的大小，这样，代码中的delete语句才能正确的释放本内存空间。另外，由于找到的堆结点的大小不一定正好等于申请的大小，系统会自动的将多余的那部分重新放入空闲链表中。 2.3申请大小的限制栈：在Windows下,栈是向低地址扩展的数据结构，是一块连续的内存的区域。这句话的意思是栈顶的地址和栈的最大容量是系统预先规定好的，在WINDOWS下，栈的大小是2M（也有的说是1M，总之是一个编译时就确定的常数），如果申请的空间超过栈的剩余空间时，将提示overflow。因 此，能从栈获得的空间较小。堆：堆是向高地址扩展的数据结构，是不连续的内存区域。这是由于系统是用链表来存储的空闲内存地址的，自然是不连续的，而链表的遍历方向是由低地址向高地址。堆的大小受限于计算机系统中有效的虚拟内存。由此可见，堆获得的空间比较灵活，也比较大。 2.4申请效率的比较：栈由系统自动分配，速度较快。但程序员是无法控制的。堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便.另外，在WINDOWS下，最好的方式是用VirtualAlloc分配内存，他不是在堆，也不是在栈是直接在进程的地址空间中保留一快内存，虽然用起来最不方便。但是速度快，也最灵活。 2.5堆和栈中的存储内容栈： 在函数调用时，第一个进栈的是主函数中后的下一条指令（函数调用语句的下一条可执行语句）的地址，然后是函数的各个参数，在大多数的C编译器中，参数是由右往左入栈的，然后是函数中的局部变量。注意静态变量是不入栈的。当本次函数调用结束后，局部变量先出栈，然后是参数，最后栈顶指针指向最开始存的地址，也就是主函数中的下一条指令，程序由该点继续运行。堆：一般是在堆的头部用一个字节存放堆的大小。堆中的具体内容有程序员安排。 排序算法插入思路：在一个有序的序列中，插入一个新的数，让这个序列依然有序。插入排序是稳定的排序，即在一个序列中，如果有两个数相等，那么他们之间的前后顺序在排序后不变。复杂度： 一般情况o(n2)，最优情况排好序的情况o(n),最差情况o(n2)，数列为逆序。算法： 冒泡思想：通过两两交换，像水中的泡泡一样，小的先冒出来，大的后冒出来。是稳定排序。复杂度：o(n2)，没有最优或最差情况。算法： 选择思路：在数列中，每次选择一个最小的值，放到新排列数列的最后面。不稳定排序。复杂度：o(n2)算法： 归并思路：分治思想解决排序。是稳定排序。复杂度：o(n lgn)。伪代码：1234567mergeSort(A,i,j)&#123; if i &lt; j mid = (i+j)/2 mergeSort(A,i,mid) mergeSort(A, mid+1,j) merge(A,i,m,g)&#125; 其中，merge的操作就是将两个基本有序的数列合并到一起。这个过程需要额外的一个数组来做临时变量。算法： 快速基本是必考的排序。思路：利用分治的思想，将大问题化为两个小问题，然后再合并。首先在一个已排序的序列中，随便选择一个数。然后将比这个数大的放在这个数右边，小的放在左边。然后对这两个子区间再排序。是不稳定的排序。复杂度：o(nlgn) 没有最优情况，最差情况是每次选择都选择到了数组的最值，这个时候分区最不平衡。一般的实现上来讲，会发生在排序的数列是逆序或者所有数列都是相等的时候。解决方法是三值取中法。算法： 堆思路：利用最大堆和最小堆进行排序。将数组整理为堆，然后每次弹出堆顶即可。复杂度：o(nlg n) 基底思路：从个位到高位，对于每一位进行排序，而每一位的排序，都视为计数排序。是稳定的排序，需要额外的空间。例图：复杂度：o((n+k)d) 算法： 桶思路：先预筛选再进行排序。把一个大的复杂的数列先按大小范围把不同元素放到不同的桶里面。然后对不同桶里面的数进行排序。稳定排序，需要额外的空间。复杂度：最优情况是o(n)，这个时候所有的元素均匀分布到各个桶里面，而且桶内元素正好有序。最坏情况是全部元素都分到一个桶里面，为o(n2)或者o(nlg n)如果桶内排序用的是快排的话。算法： 计数思路：利用数组的下标进行统计的排序。这个算法速度快(o(n),基本上这种有一定使用条件的排序算法速度上都会优于通用的排序方法。)，需要额外的空间，不适用于有负数的排序和数组中含有特别大的数的数列。复杂度：o(n+k)，k为数列中最大的数。需要额外的空间复杂度。o(k)是不稳定的排序。本质上是先统计在根据统计还原。和原来的数组已经没有关系了。算法： 睡眠这是来搞笑的。= =构造n个线程，它们和这n个数一一对应。初始化后，线程们开始睡眠，等到对应的数那么多个时间单位后各自醒来，然后输出它对应的数。这样最小的数对应的线程最早醒来，这个数最早被输出。 算法补遗查找算法 二分查找思路：折办查找，元素必须是有序的才可以。用给定值k先与中间结点的关键字比较，中间结点把线形表分成两个子表，若相等则查找成功；若不相等，再根据k与该中间结点关键字的比较结果确定下一步查找哪个子表，这样递归进行，直到查找到或查找结束发现表中没有这样的结点。复杂度: o(lg n)算法：1234567891011121314151617181920212223242526272829//二分查找（折半查找），版本1int BinarySearch1(int a[], int value, int n)&#123; int low, high, mid; low = 0; high = n-1; while(low&lt;=high) &#123; mid = (low+high)/2; if(a[mid]==value) return mid; if(a[mid]&gt;value) high = mid-1; if(a[mid]&lt;value) low = mid+1; &#125; return -1;&#125;//二分查找，递归版本int BinarySearch2(int a[], int value, int low, int high)&#123; int mid = low+(high-low)/2;//这种求mid的写法是为了防止溢出，因为high+low是有可能溢出的。 if(a[mid]==value) return mid; if(a[mid]&gt;value) return BinarySearch2(a, value, low, mid-1); if(a[mid]&lt;value) return BinarySearch2(a, value, mid+1, high);&#125; partition中位数这个算法是在乱序的数组中查找中位数的算法。利用快排关键字的查找方法a.随机选取一个关键字key，将序列二分；b.若关键字的下标大于N/2，则继续对序列的左半部分执行partition；c.若关键字的下标小于N/2，则继续对序列的右半部分执行partition；d.若关键字的下标等于N/2，则返回key。算法复杂度是o(nlg n)?. 基于流的中位数提炼一下就是利用大小堆来存储这个流的数。在存储的过程中，大堆保存中位数左边的数，小堆保存中位数右边的数。在拿到流中的数时，动态调整（在新到达的数，大堆顶，小堆顶三个数中比较，然后选则将新的数送到哪个堆中）。需要取中位数数时只要取两个堆顶即可。给一个数据流，找出中位数，由于数据流中的数据并不是有序的，所以我们首先应该想个方法让其有序。如果我们用vector来保存数据流的话，每进来一个新数据都要给数组排序，很不高效。所以之后想到用multiset这个数据结构，是有序保存数据的，但是它不能用下标直接访问元素，找中位数也不高效。这里用到的解法十分巧妙，我们使用大小堆来解决问题，其中大堆保存右半段较大的数字，小堆保存左半段较小的数组。这样整个数组就被中间分为两段了，由于堆的保存方式是由大到小，我们希望大堆里面的数据是从小到大，这样取第一个来计算中位数方便。我们用到一个小技巧，就是存到大堆里的数先取反再存，这样由大到小存下来的顺序就是实际上我们想要的从小到大的顺序。当大堆和小堆中的数字一样多时，我们取出大堆小堆的首元素求平均值，当小堆元素多时，取小堆首元素为中位数 最短路径迪杰斯特拉 动态规划不知道该怎么讲，丢个连接dp 蓄水池抽样介绍从一个长度未知或者很长的序列中随机抽取出k个元素，保证k个元素的输出是完全随机的。构造一个可以放置k个元素的蓄水池，将序列的前k个元素放入蓄水池类，然后从第k+1个元素开始，以k/n的概率来决定钙元素是否需要被替换到水池中。 实现伪代码如下：1234567Init : a reservoir with the size： k for i= k+1 to N M=random(1, i); if( M &lt; k) SWAP the Mth value and ith value end for 证明 对于第i个数(i&lt;k)，在前k步被选中的概率是1， 从第k+1步开始，i不被选中的概率为k/k+1,那么读到第n个数时， 第i个数(i&lt;k)被选中的概率 = 被选中的概率 以后每一步都不被换走的概率,即`1 k/k+1 * k+1/k+2 …n-1/n = k/n` 对于第j个数(j&gt;=k)被选中的概率为： 在他出现时被选中的概率 在他出现以后不被换走的概率,即:`k/j j /j+1 。。。n-1/n = k/n` 位运算看大佬 拉格朗日四平方和定理拉格朗日四平方和定理Leetcode 279 perfect squares四平方和定理说明每个正整数均可表示为4个整数的平方和。 任何形为4n+1的素数都能表示为两个平方数之和。用dp[i]表示i的正数组成情况时：dp[i*i] = 1;dp[i*i + a] = dp[a]+1;利用这个来进行dp递推公式的推导。 123456789101112131415161718192021class Solution &#123;public: int min(int a, int b)&#123; if (a&gt;b) return b; return a; &#125; int numSquares(int n) &#123; int *dp = new int[n+1]; for(int i =0;i!=n+1;++i)dp[i] = 4; for(int i =0;i*i&lt;=n;++i)&#123; dp[i*i] = 1; &#125; for(int a = 0;a!=n+1;++a)&#123; for(int b = 0;b*b&lt;=a;++b)&#123; dp[a] = min(dp[a],dp[a-b*b]+1); &#125; &#125; return dp[n]; &#125;&#125;; kmp和manacherkmp算法思想kmp算法的思想是利用额外的信息量来避免不必要的匹配。假设我们匹配两个串分别到了i,j时发现不匹配了。正常的算法是将计数器重新计算到匹配的开头加1.但是这么做就浪费了串0~i-1 和串0~j-1之间的串都相等的这个信息量。kmp的思路就是要利用这个额外的信息量将匹配的窗口尽量的滑动到最远。 额外的信息量额外的信息量是指前缀函数。比如对于字符串ABCDABD而言。其前缀函数的信息是： 表头 1 2 3 4 5 6 7 搜索词 A B C D A B D 部分匹配词 0 0 0 0 1 2 0 求取这个next的代码如下：1234567891011121314151617public int[] getNext(String b) &#123; int len=b.length(); int j=0; int next[]=new int[len+1];//next表示长度为i的字符串前缀和后缀的最长公共部分，从1开始 next[0]=next[1]=0; for(int i=1;i&lt;len;i++)//i表示字符串的下标，从0开始 &#123;//j在每次循环开始都表示next[i]的值，同时也表示需要比较的下一个位置 while(j&gt;0&amp;&amp;b.charAt(i)!=b.charAt(j))j=next[j]; if(b.charAt(i)==b.charAt(j))j++; next[i+1]=j; &#125; return next; &#125; 字符串匹配字符串匹配的过程和获取额外信息的函数是基本一致的。都是依照next[j]来进行（匹配失败时）下标的移动。1234567891011121314public void search(String original, String find, int next[]) &#123; int j = 0; for (int i = 0; i &lt; original.length(); i++) &#123; while (j &gt; 0 &amp;&amp; original.charAt(i) != find.charAt(j)) j = next[j]; if (original.charAt(i) == find.charAt(j)) j++; if (j == find.length()) &#123; System.out.println(\"find at position \" + (i - j)); System.out.println(original.subSequence(i - j + 1, i + 1)); j = next[j]; &#125; &#125; &#125; Reference manacher 回文子串介绍在o(n)的时空复杂度内，求出以每个字符为中心的最长回文有多长。这个算法可以求出包括奇数和偶数的回文串。算法的核心思想就是利用已经匹配的最右位置和对应的对称中心来跳过已经进行过的比较。 过程 在每两个字符中插入一个分隔符。这个分隔符在原文中没有出现，一般是用#. 然后用一个辅助数组P来记录以每个中心为最长回文传的信息。 123before : waaabwswfdafter : # w # a # a # a # b # w # s # w # f # d #P: 1 2 1 2 3 2 1 2 1 2 1 2 1 4 1 2 1 2 1 2 1 P[id]-1就是该回文子串在原串中的长度 在扫描的时候，线性的从左往右扫描。在扫描的时候，用mx在记录i在之前的回文串查找过程中，查找到的最右的位置，以及取到这个最右值时的字符位置id。 关键的比较： 12if (i &lt; mx) p[ i ] = min( p[ 2 * id - i ], mx - i ); 2*id-i求得是i关于id对称的点。这个对称点上的回文子串的长度在目前以及匹配到的结果中，和i点事一样的。（除非碰到了左边界或右边界） 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869#include&lt;iostream&gt; #include&lt;string.h&gt; #include&lt;algorithm&gt; #include&lt;utility&gt; using namespace std; char s[1000]; char s_new[2000]; int p[2000]; int Init() &#123; int len = strlen(s); s_new[0] = '$'; s_new[1] = '#'; int j = 2; for (int i = 0; i &lt; len; i++) &#123; s_new[j++] = s[i]; s_new[j++] = '#'; &#125; s_new[j] = '\\0';//别忘了哦 return j;//返回s_new的长度 &#125; int Manacher() &#123; int len = Init();//取得新字符串长度并完成向s_new的转换 int maxLen = -1;//最长回文长度 int id; int mx = 0; for (int i = 1; i &lt; len; i++) &#123; if (i &lt; mx) p[i] = min(p[2 * id - i], mx - i);//需搞清楚上面那张图含义,mx,2 * id - i的含义 else p[i] = 1; while (s_new[i - p[i]] == s_new[i + p[i]])//不需边界判断，因为左有'$',右有'\\0' p[i]++; if (mx &lt; i + p[i])//我们每走一步i，都要和mx比较，我们希望mx尽可能的远，这样才能更有机会执行if (i &lt; mx) 这句代码，从而提高效率 &#123; id = i; mx = i + p[i]; &#125; maxLen = max(maxLen, p[i] - 1); &#125; return maxLen; &#125; int main() &#123; while (printf(\"请输入字符串：\\n\")) &#123; scanf(\"%s\", s); printf(\"最长回文长度为 %d\\n\\n\", Manacher()); &#125; return 0; &#125;","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Algorithm","slug":"Algorithm","permalink":"https://nachtz.github.io/tags/Algorithm/"}]},{"title":"Defense4All 粗翻","date":"2017-02-23T05:24:31.000Z","path":"2017/02/23/SDN_defense4all/","text":"前言：Defense4All 粗翻 对Defense4All:Tutorial的粗翻，基于Google翻译加上自己修改。旨在为自己毕设提供一种设计思路。 Defense4All：教程内容 [ 隐藏 ]1 简介2 Defense4All设计3 部署替代4 Defense4All在ODL环境中5 框架视图6 应用视图7 ODL代表视图8 基本控制流程9 配置和设置流程10 攻击检测流程11 攻击减轻流程12 问题和故障排除13 连续性14 维护和升级15 新术语和概念16 其他信息16.1 安全和隐私16.2 兼容性16.3 性能和可伸缩性信息16.4 参考资料 介绍将可疑流量从正常网络路径转移到专用攻击缓解设备来进行清洗和威胁检测是一个普遍的DoS攻击环节和威胁检测策略。这些基础架构也被称为安全中心或者清洗中心，主要由第3层到第7层DoS攻击缓解设备组成。这些清洗中心可以以路径外（OOP）方式（不内嵌在本地业务流）部署在网络内的专用远程站点，因此将流量转移到这些中心是必要的。在流量清洗过程期间，攻击缓解基础设施识别并丢弃恶意IP分组，并将合法IP分组转发回其原始目标网络目的地。清洗中心可以位于企业网络，数据中心或云中，也可以作为运营商基础设施的一部分。一般来说，OOP系统中的DDoS防护包括以下主要元素： 在正常时期收集被保护网络的流量统计和对流量统计特征的学习。 受保护网络的正常流量基线是由这些收集的统计信息构建的。 认为偏离正常流量基线的流量异常可能是DoS攻击。 将可疑流量从其正常路径转移到缓解（清洗）中心，用于流量清洗，选择性源阻塞等。从清洗中心出来的干净流量被重新发往到原始目的地中。 Defense4All设计Defense4All是一种SDN安全应用程序，用于检测和缓解在不同SDN拓扑中的DoS和DDoS攻击。它实现了基于可编程流的SDN环境的OOP模式下的DoS防护。管理员可以配置Defense4All以保护某些网络和服务器，程序中将之称为受保护网络或受保护对象（POs​​）。Defense4All利用SDN功能来统计指定的流量，并在每个网络位置，为每个配置中的PO，安装针对不同协议的计数流。然后Defense4All监控所有配置的PO的流量，汇总来自所有相关网络位置的读取操作，速率和平均值。如果在特定PO的协议（例如TCP，UDP，ICMP或其余流量）中检测到与正常学习的流量行为的偏差，则Defense4All在目标PO中宣布发现基于该种协议的攻击。Defense4All在安装计数流后至少需要一个星期的学习时间，在这期间Defense4All不检测攻击。为了缓解检测到的攻击，Defense4All执行以下过程： 它确认DefensePro设备是否处于正常状态，并选择和正常工作的设备进行连接（如果DefensePro没有启动或没有心跳活动连接，则不会执行流量转移）。有关详细信息，请参阅“连续性”部分。 Defense4All使用安全策略和攻击流量的正常速率来配置DefensePro。后者能提升DefensePro对攻击的缓解。 Defense4All开始从DefensePro中监测和记录系统日志。只要它继续从DefensePro接收关于此攻击的攻击通知，Defense4All就会继续转移流量来继续进行攻击缓解，即使Vexternal FlowFilter计数器不提示流量中包含任何攻击。 Defense4All通过创建一对Vexternals并将它们映射到与DefensePro连接的所选物理PFS端口对，将所选的物理DefensePro连接映射到相关的VTN。并且会自动学习和保留VLAN标记（如果存在）。如果Defense4All已经在VTN中创建并映射了具有相同VLAN的一对Vexternals，则相同的对也被重新用于新流量的转移（而不是为相同的VTN和VLAN创建新的Vexternals）。 Defense4All在每个北向Vexternal中安装较高优先级的流过滤条目，通过该过滤条目，将攻击流量转移重定向到“北向DP-In Vexternal”。它还选择连接到所有Vexternals的Vbr的活北接口之一（可以有一个具有相同VLAN的Vbr）。Defense4All将来自“DP-Out Vexternal”的流量重新注入到选定的Vbr接口。（ 这句话看不懂 ）当Defense4All确定攻击已结束（没有来自PFC FlowFilter计数器或来自DefensePro的指示）时，它会恢复先前的流量：它停止监视有关流量的DefensePro syslog，它会删除流量转移流表项，删除“DP-In和DP-Out Vexternals“（如果这是此VTN和VLAN中的最后一次攻击），并从DefensePro中删除安全配置。Defense4All然后返回到正常监控。 在此版本中，Defense4All作为单个实例（非集群）运行，但它集成了以下主要容错功能： 它作为Linux服务运行，如果失败，它会自动重新启动。 有状态服务，会将最新的运行状态保存在可靠存储中，并能恢复运行。 它带有一个有重启和重置功能的健康跟踪器，以解决某些逻辑和老化的错误。Defense4All监控DefensePro的状态，连接到DefensePro的交换机，在各种VTN中的相关Vbr(虚拟网桥)，这些Vbr的北向接口和北Vexternals。它依此调整，取消和（重新）发起攻击流量转移。下图说明了任何给定PO的可能状态。Radware的DefensePro（DP）是具体化的AMS的示例。 PN可能状态 部署替代Defense4All支持“短转移”，即AMS（攻击减轻系统）连接到边缘路由器，从而实现只用一跳进行流量重定向。另请参见图3中的PE1和DefensePro 2。“长转向”，即AMS清洗中心位于网络中的任意远程位置，将在未来的Defense4All版本中添加。参见下图中的PE2和DefensePro 1。Defense4All支持自动和手动转移模式。手动模式即在转移前需要向用户进行确认。 基于ODL的Defense4AllDefense4All是一种用于检测和缓解DDoS攻击的SDN应用程序。应用程序通过ODC北向REST API与OpenDaylight控制器通信。通过这个API，Defense4All执行两个主要任务： 监控受保护流量的行为 - 应用程序在所选网络位置中设置流条目以读取每个PN的流量统计（从多个位置聚集针对给定PN收集的统计）。 将攻击流量转移到选定的AMS - 应用程序在选定的网络位置中设置流条目，以将流量转移到所选的AMS。当攻击完成时，应用程序将删除这些流条目，从而返回到正常操作和流量监控。Defense4All可以与设定好的AMS通信 - 例如，动态配置它们，监视它们，或者收集和操作来自AMS的攻击统计。AMS的API不是标准化的，在任何情况下都超出了OpenDaylight工作设计的范围。Defense4All包含一个参考实现可插拔驱动程序，与Radware的DefensePro AMS通信。应用程序提供其北向REST和CLI API，以允许其管理器： 控制和配置应用程序（运行时参数，ODC连接，域中的AMS，PN等等）。 从Defense4All和其他来源（如ODC，AMS）统一获取报告数据 - 操作或安全，当前或历史。Defense4All包括一个SDN应用程序框架和Defense4All应用程序本身，打包为一个单一的实体。应用程序集成到框架中是可插入的，因此任何其他SDN应用程序都可以受益于公共框架服务。这种架构的主要优点是： 更快的应用程序开发和更改 - 框架包含用于多个应用程序的公共代码，复杂元素（例如集群和存储库服务）只需要实现一次就能复用。 更快，更灵活地部署在不同的环境，形式因素，满足不同的NFR - 框架掩盖SDN应用因素，如所需的数据生存性，规模和弹性，可用性，安全性。 更强的鲁棒性 - 复杂的框架代码实现和测试一次，更清晰的关注分离导致更稳定的代码，框架可以主动增加鲁棒性，没有额外的代码在应用程序逻辑（如周期性应用程序循环）。 统一管理的共同方面 - 共同的外观和感觉。框架视图框架包含以下元素： FrameworkMain - 框架根点包含对所有框架模块和全局存储库的引用，以及部署的SDN应用程序的根（在当前版本中，框架只能容纳一个应用程序）。这也是启动，停止或重置框架（连同其管辖的应用程序）的Web服务器，运行Jersey RESTful Web服务框架的Jetty Web服务器，使用Jackson解析器解析JSON编码参数。REST Web服务器为框架运行一个servlet，同时为每个已部署的应用程序（目前只有一个）运行单独一个servlet。所有REST和CLI API都通过此REST Web服务器提供服务。 FrameworkRestService - 构成响应框架REST请求（获取最新的Flight Recorder记录，执行恢复出厂设置等）的框架servlet的一组类。FrameworkRestService针对FrameworkMgmtPoint调用控制和配置方法，并且报告它直接从相关存储库检索信息。它调用专门的FlightRecorder的方法来获取Flight Recorder。 FrameworkMgmtPoint - 驱动器控制和配置命令（启动，停止，重置，设置主机的地址，等等）的点。FrameworkMgmtPoint反过来按照正确的顺序调用其他相关模块的方法。它将生命周期请求（开始，停止，重置）直接转发到FrameworkMain，以按正确的顺序驱动它们。 Defense4All应用程序 - 任何SDN应用程序（在本例中为Defense4All）都应该Implement/extendAppRoot对象。SDN应用程序没有“main”，并且它们的生命周期（启动，停止，重置）由对应用程序根对象操作的框架管理，然后应用程序根对象驱动应用程序中的所有生命周期操作。此模块还包含回框架的引用，允许应用程序使用框架服务（例如创建Repo并记录Flight Record）和常见实用程序。 通用类和实用程序 - 一个方便的类和实用程序库，任何框架或SDN应用程序模块都可以从中受益。示例包括包装线程服务（用于异步，定期或后台执行），字符串的短散列和用户确认。 存储库服务 - 框架理念中的关键元素之一是将计算状态与计算逻辑分离。所有持久状态都应该存储在一组存储库中，然后可以在不知道计算逻辑（框架或应用程序）的情况下进行复制，缓存，分发。存储库服务包括RepoFactory和Repo或其等价物 - EntityManager。RepoFactory负责与底层存储库插件服务建立连接，实例化新的请求存储库，并返回对现有存储库的引用。所选的底层存储库服务是通过Cassandra NoSQL DB的Hector Client。Repo呈现单个DB表的抽象。它使得能够只用表键就能读取整个表，（表仅由单个主键索引），记录单个单元，以及依照控制要求写入记录。并能够写入子记录（仅具有单元的一部分）。在这种情况下，显示的单元格覆盖存储库中的现有单元格。存储库中的其他单元格保持不变。与关系数据库（其中所有列都必须预先指定（在模式设计中）相反），Repo利用底层Cassandra支持来在相同的表中包含不同列的集合（记录），其中一些列可能甚至没有预先定义。此外，具有新列的单元可以在运行中添加或移除。RepoFactory和Repo（以及它的等价物Entity Manager）构成了一个基于与Cassandra Repository集群通信的Hector客户端库之上，针对框架和SDN应用程序目标的方便的库。Cassandra集群伸缩，跨Cassandra集群成员分发数据，以及配置读/写热切和一致性大部分封装在此层中。 日志记录和Flight Recorder服务 - 日志记录服务使用Log4J库记录错误，警告，跟踪或提示消息。这些日志主要用为Defense4All开发人员所用。管理员可以从错误日志中获取有关故障的其他详细信息。FlightRecorder记录由Defense4All模块记录的所有航班记录，包括从外部网络元件（如ODC和AMS）接收的信息。然后，它允许用户或管理员通过REST API或CLI获取该信息。航班记录可以按类别（可以指定零个或多个）和时间范围进行过滤。FlightRecorder将所有航班记录存储在其自己的Repo中（其他repo从存储在其他区域的记录库中使用有效时间范围检索获取这些记录）。由于所有航班记录都存储在Cassandra中，Defense4All可以保留的航班记录数量仅受所有Cassandra服务器的底层持久存储容量的限制，因此即使在单个Cassandra实例上，也可以保留几个月的历史信息。 HealthTracker - 在Defense4All的运行时进行统一健康状况并响应严重恶化的行为。任何模块在感测到其中或任何其他模块中的意外和/或错误行为时，可以在HealthTracker中记录“健康问题”，并提供健康问题的症状。这不会直接触发Defense4All终止。这意味着在短时间内聚合的许多健康问题可能意味着Defense4All存在问题，但是偶发性和/或间歇性操作性“打嗝”可以被忽略，即使Defense4All保持小于100％可操作管理员可以始终将其重置以完全恢复）。结果，每个非永久性健康问题都随着时间的推移逐渐减弱。如果Defense4Al健康恶化低于预定义阈值，HealthTracker会根据健康问题的性质触发响应操作。重启可以治愈瞬态问题，因此HealthTracker触发Defense4All终止（作为Linux服务运行，Defense4All自动重新启动）。要从更永久的问题中恢复，HealthTracker可能还会触发Defense4All重置。如果这没有帮助，下次HealthTracker尝试更深层次的重置。作为最后手段，可以建议管理员执行出厂重置。 ClusterMgr - 当前未实现，所以不翻译了，保留机翻。此模块负责管理一个Defense4All集群（与Cassandra或ODC集群分开，建模为单独的层集群）。集群的Defense4All提高了高可用性和可扩展性。Defense4All框架或应用程序中的任何模块都可以向ClusterMgr注册集群操作，指定其功能是由单个还是由多个/所有活动实例（在不同的Defense4All集群成员上运行）执行。当集群成员资格更改时，ClusterMgr会通知每个模块中的每个实例其在该模块的集群操作中的角色。如果存在单个活动实例，则会通知该实例在集群中的角色，而所有其他实例都会通知它们处于待机模式。如果有多个活动实例，则通知每个活动实例关于该范围中的活动实例数及其逻辑枚举。所有状态都存储在一个全局可访问和共享的存储库中，所以模块的任何实例都是无状态的，并且可以在每个成员更改后执行任何角色。例如，在成员资格变化N之后，实例可以被枚举为7中的2个，作为执行工作的相关部分的结果。在成员变化N + 1，相同的实例可以枚举6中的5，并且执行分配给5而不是2的工作部分。跳过对等消息服务，ClusterMgr可以提供用于更协调的跨实例操作。 Defense4All应用程序是高度可插拔的。它可以适应不同版本的ODC和不同AMS的不同攻击检测机制，不同攻击缓解驱动程序和驱动程序（称为代表）。Defense4All应用程序包括“核心”模块和实现定义明确的Defense4All应用程序API的“可插拔”模块。 应用程序视图以下是对Defense4All应用程序模块的描述： DFAppRoot - Defense4All应用程序的根模块。Defense4All应用程序没有“main”，它的生命周期（启动，停止，重置）由对此模块操作的框架管理，从而驱动Defense4All应用程序中的所有生命周期操作。DFAppRoot还包含对所有Defense4All应用程序模块（核心和可插入），全局存储库和回到框架的引用的引用，从而允许Defense4All应用程序模块使用框架服务（例如创建Repo并记录航班记录）和公用实用程序。 DFRestService - 构成Defense4All应用程序servlet的一组类，用于响应Defense4All应用程序REST请求。DFRestService针对DFMgmtPoint调用控制和配置方法，并且报告它直接从相关存储库检索信息。对于飞行记录，它调用针对FlightRecorder的方法。 DFMgmtPoint - 驱动器控制和配置命令（如addams和addpn）的点。DFMgmtPoint反过来按照正确的顺序调用其他相关模块的方法。 ODL Reps - 用于不同版本的ODC的可插拔模块集。包括两个子模块中的两个功能：相关流量的统计收集和流量转移。这两个子模块遵循StatsCollectionRep DvsnRep API。ODL Reps在图6和其后的描述中详细描述。 SDNStatsCollector - 负责在指定的网络位置（物理或逻辑）为每个PN设置“计数器”。计数器是ODC可用的网络交换机和路由器中的一组OpenFlow流条目。SDNStatsCollector定期从这些计数器收集统计信息，并将它们馈送到SDNBasedDetectionMgr（请参阅下面的描述）。模块使用SDNStatsCollectionRep设置计数器并从这些计数器读取最新的统计信息。stat报告由读取时间，计数器规范，PN标签和trafficData信息列表组成，其中每个trafficData元素包含在计数器位置中为&lt;protocol，port，direction&gt;配置的流条目的最新字节和分组值。协议可以是{tcp，udp，icmp，other ip}，端口是任何第4层端口，方向可以是{inbound，outbound}。 SDNBasedDetectionMgr - 用于可插拔基于SDN的检测器的容器。它将从SDNStatsCollector接收的统计信息报告给插入的基于SDN的检测器。它还从关于结束攻击的攻击分辨点（参见下面的描述）馈送所有基于SDN的检测器通知（以允许检测机制的重置）。 RateBasedDetector子模块 - 该检测器针对每个PN了解其随时间的正常流量行为，并在检测到流量异常时通知AttackDecisionPoint（参见下面的描述）。对于每个PN的每个协议{TCP，UDP，ICMP，其他IP}，RateBasedDetector保持字节和分组的最新速率和指数移动平均值（基线）以及最后读取时间。检测器保持每个计数器的这些值以及每个PN的所有计数器的聚合。在两个计算级别（计数器和PN聚合）的组织允许更好的可扩展性（例如使用集群ODC，其中每个实例负责从一部分网络交换机获得统计数据，并绕过ODC单实例映像API）。这样的组织还使得能够进行更精确的统计收集（避免在非常小的时间间隔期间收集所有统计的困难）。统计在计数器级处理，并且在PN级定期聚合。持续检测到流量异时，RateBasedDetector通知AttackDecisionPoint进行攻击检测。然后，在一段时间内没有异常，就通知检测器停止该攻击检测。检测器可以指定检测持续时间，在该检测持续时间内检测有效。之后，检测过期，但可以“延长”另一个关于相同攻击的通知。 AttackDecisionPoint - 此模块负责在攻击生命周期内应对攻击。它可以从多个检测器接收攻击检测信息。Defense4All支持RateBasedDetector，外部检测器（未来版本可用）和基于AMS的检测器参考实现（基于Radware的DefensePro）。在当前版本中，AttackDecisionPoint完全尊重每次检测（最大检测器置信度和最大检测置信度）。它为每次检测到新攻击的流量（PN，协议和端口）声明一个新的攻击，并且为现有（已声明的）攻击增加更多的检测。模块定期检查所有攻击的状态。只要至少有一个未到期的检测（每个检测都有一个到期时间），就会继续声明攻击。如果对于给定攻击的所有检测都过期，则AttackDecisionPoint声明攻击已经结束。模块通知MitigationMgr（见下面的描述）开始减轻任何新的声明的攻击。它通知MitigationMgr停止缓解已结束的攻击，并通知detectMgr重置对攻击刚刚结束的流量的统计计算。 MitigationMgr - 用于驱动可插拔攻击缓解程序的容器。MitigationMgr维护所有攻击缓解，并负责通知来自AttackDecisionPoint的攻击缓解请求的结果。它包含预先排好序列的MitigationDriver子模块，并尝试按照该顺序满足每个攻击缓解。如果MitigationDriveri向MitigationMgr指示它不缓解一个攻击缓解（由于每个PN偏好，AMS资源的不可用性，网络问题等），MitigationMgr将尝试通过MitigationDriveri + 1进行缓解。如果没有插入的MitigationDrivers处理缓解，则它仍处于“未缓解”状态。 MitigationDriverLocal - 此缓解驱动程序负责在其管理范围内使用AMS来驱动攻击缓解。当请求缓解攻击时，此缓和剂执行以下步骤顺序： 它向可插入DvsnRep（见下面的描述）咨询关于从每个相关网络位置的每个管理的AMS的拓扑可行的转移选项。在此版本中，转移始终从安装统计计数器的位置执行。 MitigationDriverLocal在所有可行选项中选择一个AMS（在第一个版本中，只选择列表中的第一个）。 在指示将业务转移到每个AMS之前，它随机分配所有AMS（每个转向源可以有与其相关联的不同AMS）。这是通过插入AMSRep完成的。 MitigationDriverLocal指示DvsnRep，将来自每个源NetNode（在此版本中，NetNode为SDN交换机）的流量转移到与该NetNode相关联的AMS。转移可以仅用于入站流量，也可以用于入站和出站流量。 攻击缓解驱动程序通知AMSBasedDetector开始监视所有AMS中的攻击状态，并将攻击检测馈送到AttackDecisionPoint。 在未来版本中，MitigationDriverLocal会监视所有AMS和网络拓扑的相关部分的运行状况，可以重新选择AMS（如果该AMS缓解失败），或者依照网络拓扑变动重新选择AMS。当缓解应该结束时，MitigationDriverLocal通知AMSBasedDetector停止监视已结束攻击的攻击状态，通知DvsnRep停止对所有AMS的流量转移以进行此缓解，最后通知AMSRep可选地清除每个缓冲中的所有缓解相关配置集相关的AMS。 AMSBasedDetector - 此可选模块（可以打包为AMSRep的一部分）负责监视/查询AMS的攻击缓解。注册为检测器，此模块然后可以通知AttackDecisionPoint有关攻击持续和结束。它仅监视指定的AMS，并且仅监视指定（攻击的）流量。 AMSRep - 用于不同AMS的可插拔模块。该模块遵守AMSRep API。它可以支持所有引入的AMS的配置（永久或在攻击缓解之前/之后）。它还可以接收/查询安全信息（攻击状态），以及操作信息（健康，负载）。AMSRep模块是完全可选的 - AMS可以在外部配置和监控。在许多情况下，攻击可以继续通过SDN计数器单独监控。Defense4All包含与Radware的DefensePro AMS通信的参考实现AMSRep。 ODL代表视图上图描述了Defense4All应用程序ODL Reps模块集结构。不同版本的OFC可以用ODL Reps模块集的不同版本实现。ODLReps包括两个功能：相关流量的统计收集和流量转移。这两个功能或任一功能可以在给定部署中使用。因此，它们在与ODC通信，并保存ODC的所有一般信息（见下文）具有相通之处。 ODL Reps支持两种类型的SDN交换机：sdn-hybrid，支持SDN和传统路由; sdn-native，支持仅SDN路由。在传统路由中，通过对预设流表和动作“send to normal”的流条目进行计数来计算sdn混合交换机上的流量。在sdn-native交换机上计数流量需要一个显式路由操作（将流量发送到哪个输出端口）。Defense4All通过要求一个sdn本地交换机避免学习所有路由表，该交换机或多或少是相对于流量路由的有线路径（即，进入端口1的流量通常退出端口2，进入端口3的流量通常退出端口4反之亦然）。（Defense4All avoids learning all routing tables by requiring an sdn-native switch which is more or less a bump-in the wire with respect to traffic routing (that is, traffic entering port 1 normally exits port 2 and traffic entering port 3 normally exits port 4 and vice versa).）这种交换机允许简单地对流条目进行编程，以便计数流量或者将流量转移到附接的AMS /从附接的AMS转移流量。当Defense4All编写具有包括端口1的选择标准的流量计数流条目时，其操作被输出到端口2，并且类似地被输出从3到4.在未来的版本中，该限制被排除。 以下是子模块的描述： StatsCollectionRep - 该模块遵守StatsCollectionRep API。其主要任务是： 在网络中提供计数器展示位置NetNodes。提供的NetNodes是为PN定义的所有NetNode。这基本上映射了哪些SDN交换给定PN流的业务。 在选定的NetNodes中添加一个平时计数器，以收集给定PN的统计信息。StatsCollectionRep为每个PN中的NetNode创建一个单独的计数器。（总体上，NetNode可以具有用于不同PN的多个计数器;并且PN可以在为给定PN指定的NetNode中具有多个计数器）。StatsCollectionRep将NetNode中的计数器的安装转换为为NetNode端口中的每个“北向接口”编程四个流条目（对于TCP，UDP，ICMP和其余IP），从客户端到受保护的PN进入SDN交换机。例如，StatsCollectionRep对具有三个端口的SDN交换机中的给定PN 12流条目添加，其中PN的入站业务进入OFS。并且，如果指定另一个NetNode（SDN交换机）使该PN的入站流量通过两个端口进入，则StatsCollectionRep在该第二个NetNode中为该PN添加八个流条目。 删除一个平时计数器。 读取指定计数器的最新计数器值。StatsCollectionRep返回在每个方向上（每个方向上当前只支持“从北向南”）为每个协议端口计数的最新字节和分组的向量，以及从ODC接收到读取的时间。 DvsnRep - 该模块遵守DvsnRep API。其主要任务是： 将指定NetNode的转移属性返回给定的AMS。在这个版本中，如果这样的转移是拓扑可行的（AMS直接附加到指定的NetNode被建模的SDN交换机上，则返回空属性，否则不返回任何属性，这在将来的版本中留有用于远程转移的空间，每个远程AMS的拓扑成本，例如延迟，带宽预留和成本）。 通过AMS转发（攻击）来自指定NetNode的流量。因此，新的流条目优先于和平时段的流条目。DvsnRep编程流条目，以将每个“北向接口”的入站攻击流量（如果PN需要的话，也可以为所有流量）转移到AMS“北”端口。如果已经为该PN指定了“对称转移”（对于入站和返回，出站业务），DvsnRep编程另一组流条目以将来自每个“南业务端口”的受攻击（或所有）流量转移到AMS“南”港口。在sdn混合交换机部署中，DvsnRep为从AMS南端口返回的入站流量添加流条目，并将操作发送到正常，并且类似地，它为来自AMS北端口的出站返回流量添加流条目，也送正常。在SDN本地交换机中，操作是发送到正确的输出端口，但是如果这种情况下，过程对于确定正确的端口更复杂。北端口MAC学习用于从分组中的源/目的MAC确定正确的输出端口。这种流条目的方案适用于TCP，UDP和ICMP攻击。对于“其他IP”攻击，流条目编程更复杂，这里为了清楚起见而被抑制。被编程为转移（但仍然计数）业务的流条目的集合包括“攻击业务量楼层”。可能有许多攻击流量楼层，所有这些都优先于和平时间统计收集楼层（通过编程较高优先级流条目）。额外的攻击（除了“其他IP”攻击，这是一种特殊情况，在此被抑制）创建具有高于先前设置的攻击流量楼层的优先级流量楼层。攻击可以完全或部分地“早期”攻击（例如，通过TCP的TCP端口80，反之亦然），或者不连接（例如TCP和UDP）。统计收集来自所有交通楼层，包括平时和攻击。基于SDN的检测器将所有统计数据聚合为总速率，从而确定攻击是否仍在进行中。（请注意，黯淡的和平时间计算的交通可能显示零利率，并且计数由较高优先权楼层计数器补充）。在细看 结束转移。DvsnRep删除相关的攻击流量层（即从NetNode中删除其所有流条目）。注意，这既不影响已移除楼层“上方”的流量层，也不影响“下面的流量层”。此外，基于SDN的检测器从剩余楼层的计数器接收相同的累计费率，因此其操作也不受影响。 ODLCommon - 此模块包含编程ODC中流条目所需的所有常见元素。这允许通过StatsCollectionRep和DvsnRep对配置的ODC（在该版本中，至多一个）进行相干编程。例如ODLCommon实例化与ODC的连接，维护分配给每个ODC的编程流条目和cookie的列表。它还维护对DFAppRoot和FrameworkMain的引用。为每个受保护链路添加sdn本地NetNode时ODLCommon（输入到输出端口对）添加2个流条目，以在两个端口之间传输流量（进入北端口的流量路由到南端口，反之亦然）。ODLCommon为连接到AMS的每个端口添加两个流条目，以阻止返回ARP流量（以便在未配置AMS的情况下避免ARP洪泛）。该“公共业务层”流条目被设置为具有最低优先级。他们的柜台既不是统计收集也不是交通分流。当删除NetNode时，ODLCommon删除此公共流量底层流条目。 FlowEntryMgr - 此模块提供了一个API，用于对ODC管理的SDN交换机中的流条目执行操作，并检索有关ODC管理的所有节点的信息。流条目操作包括在指定的NetNode（SDN交换机/路由器）中添加指定的流条目，移除流条目，切换流条目，获得流条目的详细信息以及读取由流条目收集的统计信息。FlowEntryMgr使用连接器模块与ODC通信。 连接器 - 此模块提供了包括REST通信的与ODC通信的基本API调用。在使用指定的ODC初始化连接详细信息后，连接器允许从ODC获取或删除数据，以及将数据发布或放入ODC。 ODL REST Pojos - 此组Java类是ODC REST API的一部分，指定参数的Java类和与ODC交互的结果。 基本控制流程控制流在逻辑上根据模块运行时依赖性排序，因此如果模块A依赖于模块B，则应在模块A之前初始化模块B，并在模块A之后终止。Defense4All应用程序模块依赖于大多数Framework模块，WebServer除外。 启动 - Defense4All初始化所有模块并重新应用以前配置的基础架构和安全设置，从持久性存储库获取它们。在启动过程结束时，Defense4All恢复其先前的操作。 终止 - 重新启动 - Defense4All将任何相关数据保存到稳定的存储库中，并自行终止。如果终止是重新启动，则自动重新启动机制重新启动Defense4All。否则（如升级）Defense4All不会自动重启。 复位 - 在此流程中，所有模块都复位为出厂设置。这意味着将删除所有动态获取的数据以及用户配置。配置和设置流程 OFC（OpenFlowController = ODC） - 当DFMgmtPoint从DFRestService接收到添加OFC的请求时，它首先在OFC的Repo中添加OFC记录，然后通知ODLStatsCollectionRep和ODLDvsnRep，它们又通知ODL发起到添加的OFC（ODC）。ODL实例化用于与ODC通信的REST客户端。 NetNode - 可以添加多个NetNodes。每个NetNode对交换机或类似的网络设备及其流量端口，受保护的链路和与AMS的连接建模。当DFMgmtPoint从DFRestService接收到添加NetNode的请求时，它首先在NetNodes Repo中记录添加的NetNode，然后通知ODLStatsCollectionRep和ODLDvsnRep，然后通知MitigationMgr。ODLStatsCollectionRep和ODLDvsnRep然后通知ODL，并且ODL安装低优先级流条目以在受保护链路的端口对之间传递流量。MitigationMgr通知MitigationDriverLocal，它更新其NetNode-AMS连接组以从给定的NetNodes中转移AMS的一致性分配。 AMS - 可以添加多个AMS。当DFMgmtPoint从DFRestService接收到添加AMS的请求时，它首先在AMS的Repo中记录添加的AMS，然后通知AMSRep。AMSRep可以选择在添加的AMS中预配置保护功能，并开始监控其运行状况。 PN - 可以添加多个PN。当DFMgmtPoint从DFRestService接收到添加PN的请求时，它首先在PN的Repo中记录添加的PN，通知MitigationMgr，然后最终通知DetectionMgr。MitigationMgr通知MitigationDriverLocal，然后通知AMSRep。AMSRep可以预配置此PN的AMS以及其EventMgr以接受与该PN的业务相关的事件。DetectionMgr通知RateBasedDetector，然后通知StatsCollector。StatsCollector查询ODLStatsCollectionRep可能放置此PN的统计信息收集计数器。ODLStatsCollectionRep返回为此PN配置的所有NetNodes（如果没有配置，则返回当前已知为Defense4All的所有NetNodes）。StatsCollector“选择”计数器位置选项（此版本中唯一可用的选项）。对于每个NetNode，它然后询问ODLStatsCollectionRep以创建用于主题PN的计数器。计数器本质上是在每个北通信端口上针对感兴趣的协议（TCP，UDP，ICMP和其余IP）设置的一组流条目。计数器被给予优先级，并且这构成了平时通信量楼层（通过周期性地读取所有计数器流条目通信量计数值来监视通信量）。因为PN可以在重新启动时被重新引入，或者网络拓扑的改变可能需要重新计算计数器位置，所以一些/所有计数器可能已经就位。仅添加新计数器。不再删除的计数器。ODLStatsCollectionRep根据NetNode类型配置流条目。对于混合NetNodes，流条目操作是“发送到正常”（继续到传统路由），而对于本地NetNodes，操作是匹配输出端口（在每个受保护的链路中）。OdlStatsCollectionRep调用ODL来创建每个指定的流条目。后者调用FlowEntryMgr和Connector将请求发送到ODC。 攻击检测流程周期性地，StatsCollector请求ODL StatsCollectionRep向ODC查询每个配置的PN的每个集合计数器的最新统计。ODLStatsCollectionRep调用FlowEntryMgr以获取计数器中每个流条目的统计信息。后者调用连接器从ODC获取所需的统计信息。 ODLStatsCollectionRep将获得的结果聚合在stats（每个协议的最新字节和包读取）向量中，并返回该向量。StatsCollector将每个计数器stats向量提供给DetectionMgr，然后它将stats向量转发到RateBasedDetector。RateBasedDetector维护每个计数器的统计信息以及每个PN的聚合计数器统计信息。统计信息包括先前读取的时间，以及对于每个协议的最新速率和指数平均值。 RateBasedDetector检查与平均值的显着和延长的最新速率偏差，并且如果在PN聚合等级中发现这样的偏差，则它通知攻击判断点关于攻击检测。只要偏差继续，RateBasedDetector继续通知AttackDecisionPoint关于检测。它为每个检测通知设置到期时间，并且可重复的通知基本上延长检测到期。 AttackDecisionPoint尊重所有检测。如果它已经声明对该协议端口的攻击，则AttackDecisionPoint将附加检测与该现有攻击相关联。否则，它会创建一个新的攻击，并通知MitigationMgr缓解该攻击（如下所述）。AttackDecisionPoint定期检查每个实时攻击的所有检测的状态。如果所有检测已过期，AttackDecisionPoint声明攻击结束，并通知MitigationMgr停止缓解攻击。 攻击缓解流程MitigationMgr在接收到来自AttackDecisionPoint的缓解通知时，尝试找到插入的MitigationDriver来处理缓解。目前，它只请求插入MitigationDriverLocal。 MitigationDriverLocal检查是否存在已知，实时和可用的AMS，受攻击（或所有）流量可以从受攻击流量流经的NetNodes转向。它选择一个合适的AMS并在将攻击流量转移到所选择的AMS之前对其进行配置。例如，MitigationDriverLocal从Repo检索相关的协议平均值，并通过AMSRep在AMS中配置它们。 MitigationDriverLocal然后请求ODLDvsnRep将来自PN流量流经的每个NetNode的受攻击的PN协议端口（或所有PN）流量转移到所选择的AMS。 ODLDvsnRep创建新的最高优先级流量层（其包含优先级高于先前设置的流量层中的任何流条目的流条目）。流量层包含所有流条目，以转移和计数从每个入口/北行流量端口到AMS的流量，并且从AMS返回到相关输出（南向）端口。可选地，转向可以是“对称的”（在两个方向上），在这种情况下，流条目被添加以将流量从南向端口转移到AMS中，并且从AMS返回到北向端口。注意，StatsCollector将此添加的流量地板视为任何其他（？），并将获取的统计信息从此层传递到DetectionMgr / RateBasedDetector。因为对于给定的PN，流量底板被聚合（在相同的NetNode中以及在NetNodes中），所以合并的速率保持与转移之前相同。与ODLStatsCollectionRep一样，ODLDvsnRep也使用较低级别的模块在所需的NetNodes中安装流条目。 最后，MitigationDriverLocal通知AMSRep可选地开始监视此攻击，并通知AttackDecisionPoint如果攻击继续或新的攻击发展。AMSRep可以通过AMSBasedDetector模块来实现。 如果MitigationDriverLocal找不到合适的AMS，或无法配置其任何缓解步骤，则它将中止缓解尝试，异步通知MitigationMgr。减缓措施然后保持在“无资源”状态。 当MitigationMgr接收到停止缓解攻击的通知时，它会将此通知转发到相关（且目前是唯一的）MitigationDriver，MitigationDriverLocal。MitigationDriverLocal在缓解开始时反转动作。它通知AMSRep停止监视此攻击，取消被攻击流量的转移，最后通知AMSRep可选地删除预缓解配置。 问题和故障排除(defense4all已经停止开发了，所以这部分无所谓了)除了下面列出的过程，还参考Defense4All日志有关您遇到的具体问题的信息。Defense4All日志位于/var/log/Defense4All/server.log。 Defense4All无法启动 - 如果WebServer无法启动，请检查是否与端口号存在冲突。Defense4All使用端口8086.如果RepoFactory无法初始化，请检查Cassandra服务是否正在运行（sudo服务Cassandra停止/启动/重新启动）。如果Defense4All无法初始化，则问题可能在于系统资源（如线程或内存）。尝试重新启动机器。另一个问题可能会损坏Cassandra DF DB（键空间）。如果是，请尝试执行还原或重置（请参阅准则）。 Defense4All无法终止 - 可能是其WebServer崩溃。在这种情况下停止Defense4All的唯一方法是使用以下命令杀死其JVM Linux进程：kill -9 Defense4All无法重置 - 启动Defense4All的一些问题也可能适用于重置。具体来说，Cassandra服务应该重置。如果重置失败，您可能需要手动清除Cassandra，如下所示： 卡桑德拉 - 克利drop keyspace DF;放弃;Defense4All无法添加OFC - 检查故障原因（REST或CLI）。除了不正确的参数之外，问题可能是添加的PFC不存在或在API中指定的可寻址性（地址+端口）或安全性（用户+密码）。此外，Cassandra服务应该启动。 Defense4All无法添加NetNode - 检查故障原因（REST或API）。除了不正确的参数，Cassandra服务可能已关闭。 Defense4All无法添加AMS - 检查故障原因（REST或API）。除了不正确的参数，Cassandra服务可能已关闭。另外，问题可能在于AMS不存活或未连接。 Defense4All无法删除AMS - 检查故障原因（REST或API）。除了不正确的参数，Cassandra服务可能已关闭。另外，问题可能在于AMS不存活或未连接。 Defense4All无法添加PO - 检查失败原因（REST或API）。除了不正确的参数，Cassandra服务可能已关闭。此外，问题可能是PFC可能不存在并连接。 Defense4All无法删除PO - 检查失败原因（REST或API）。除了不正确的参数外，Cassandra服务可能已关闭。此外，问题可能是DF_GLOBAL_PNS表（列族）已损坏，因此应该完全删除，如下所示： Cassandra-cli使用DF;截断列族DF_GLOBAL_PNS;另一个问题可能是控制器没有启动，所以Defense4All无法删除它已经设置。 Defense4All无法检索/转储/清理飞行记录器日志记录 - 检查故障原因（REST或API）。除了不正确的参数外，Cassandra服务可能已关闭。此外，问题可能是FWORK_FLIGHT_RECORDER_EVENTS或FWORK_FLIGHT_RECORDER_SLICES表（列族）已损坏，因此两者都应完全删除，如下所示： Cassandra-cli“使用DF;截断列族FWORK_FLIGHT_RECORDER_EVENTS;截断列族FWORK_FLIGHT_RECORDER_SLICES;警告：截断这些列族将导致当前存储在Cassandra中的所有航班记录的丢失。 Defense4All无法检索攻击或缓解 - 检查失败原因（REST或API）。除了不正确的参数外，Cassandra服务可能已关闭。此外，问题可能是DF_GLOBAL_ATTACKS / DF_GLOBAL_MITIGATIONS表（列族）已损坏，因此应该完全删除，如下所示： Cassandra-cli使用DF;截断列族DF_GLOBAL_ATTACKS或DF_GLOBAL_MITIGATIONS;警告：截断这些列族将导致丢失当前攻击和缓解的所有记录。在这种情况下，流量重定向流条目可能需要从所有相关的NetNodes手动删除（寻找优先级5X，7X，9X，等等，与action重定向）。 Defense4All操作错误和故障 - 根据错误/故障的性质，外部实体（Cassandra，PFC，NetNodes，AMS）的活性可能需要检查/重新启动。如果是内部Defense4All错误，应按此顺序尝试以下恢复步骤： Defense4All重启重新启动Defense4All宿主机Defense4All重置并可能还原到较早的状态（以及手动清理由Defense4All设置的流条目和AMS配置）。未检测到攻击 - 检查Defense4All日志，以查看在stats收集和检测机制中是否记录了任何错误。检查PFC和相关NetNodes是否存活。检查与平均值相比的最新速率。平均值可能偏斜，但重置Defense4All在攻击期间没有帮助，因为Defense4All将获得歪斜的平均值。等待攻击结束，然后重置Defense4All，并重新添加受攻击的PO。 缓解状态NO_RESOURCES - 这意味着Defense4All mitigationDriverLocal无法驱动此缓解，因为内部Defense4All错误或缺少AMS资源。如果确实没有AMS资源，则不需要恢复。否则检查相关AMS的活性。还要检查Cassandra是否正在运行，如果PFC已启动，并且如果相关的NetNode正在运行。如果存在Defense4All内部错误（根据Defense4All日志），则可能会在DF_GLOBAL_ATTACKS / DF_GLOBAL_MITIGATIONS表（列系列）中出现损坏，因此应全部删除，如下所示： Cassandra-cli使用DF;截断列族DF_GLOBAL_ATTACKS或DF_GLOBAL_MITIGATIONS;后续检测将重新创建相关的攻击和缓解记录。如果这没有帮助，请重新启动Defense4All。 缓解未终止 - 清除此缓解中的外部元素，如下所示： 手动删除相关攻击。重新启动Defense4All。重置Defense4All。连续性服务连续性（而不是高可用性）在这里定义为在存在中断事件的情况下以可承受的成本提供所需级别的服务的能力，其中 中断事件可以是加载，更改，逻辑错误，故障和灾难，管理操作（如升级），外部攻击等。服务级别可以包括响应时间，吞吐量，数据/操作的生存性，安全/隐私等。对于每种类型的事件，在不同的事件处理阶段，所需的服务级别可以针对每个服务功能而不同。成本可以包括人（数量，专业知识），设备（硬件，软件），设施（空间，电力）。集群和容错 - 集群有助于解决可伸缩性和高可用性。如果其中一个集群成员失败，另一个集群成员可以快速承担其责任。这克服了成员故障，成员托管机器故障和成员网络连接故障。Defense4All集群安排在未来版本。在版本1.0中，Defense4All作为Linux可重新启动服务运行，因此如果它失败，托管Linux操作系统恢复Defense4All。这可以克服间歇性/偶发性Defense4All故障。Defense4All宿主机的故障意味着更长的时间和温和的额外的人类努力恢复机器及其托管的Defense4All。如果机器无法启动，Defense4All可以在网络中的另一台机器上启动。为了确保Defense4All恢复其操作（而不是从头开始重新启动），必须在该计算机上预加载Defense4All（最新或更早）状态快照。非集群环境会影响从机器故障中恢复的时间和人力。时间因素不那么重要，因为Defense4All运行路径不足，所以其较长的非可用性期间意味着较长的时间来检测和减轻新的攻击。 状态持久性 - Defense4All保持在同一台机器上运行的Cassandra DB中的状态。在版本1.0中，仅配置一个Cassandra实例集群。只要本地稳定存储不会崩溃，Linux4重新启动Defense4All服务就能使Defense4All从Cassandra快速检索其最新状态并恢复其最新操作。在发生故障和重新启动承载Defense4All的机器时也会发生同样的情况。采取Defense4All状态备份，并在另一台机器上恢复允许恢复该机器上的Defense4All操作。多节点Cassandra集群（计划用于未来版本）将增加状态持久性，同时减少恢复时间和工作量。 重新启动过程 - 当Defense4All（re）启动时，它首先检查保存的配置数据，并对所有相关模块重新执行配置步骤，驱动任何相关的外部编程和/或配置操作（例如针对PFC或AMS设备），例如，重新添加PO。此配置重放和原始配置之间的唯一区别是，保留任何动态获取的数据，例如所有PO统计信息。这允许轻松达到内部一致性，特别是在Defense4All或其主机计算机崩溃的情况下。当针对外部实体重放配置动作派生时，例如添加缺失的PO统计计数器，并且去除不再需要的计数器，也达到与外部实体的一致性。Defense4All变得可操作（启动其Web服务器），让您或一些其他组件根据可能的更改完成Defense4All缺少的配置，而Defense4All关闭。这导致达到端到端的一致性。 Reset - Defense4All允许您重置其动态获取的数据和配置信息（恢复出厂设置）。这使您能够克服许多逻辑错误和错误配置。注意，Defense4All重新启动或故障转移不会克服这样的问题。因此，这种机制是对重新启动 - 故障转移机制的补充，通常应该作为最后手段应用。 故障隔离和健康跟踪器 - 在Defense4All中，故障隔离以立即恢复或补偿（尽可能多）失败的形式发生，并在称为健康跟踪器的特殊模块中记录故障。除了少数实质性故障（例如无法启动框架），任何模块中的任何故障都不会立即导致Defense4All停止。相反，每个模块在其范围内记录每个故障，提供严重性规范和故障持久性的指示。如果所有故障的组合严重性（永久或临时）超过全局设置的阈值，HealthTracker会触发Defense4All关闭（并由Linux进行复原）。以后，永久或重复的临时故障将导致HealthTracker触发Defense4All软动态和动态重置（动态获取的数据）或建议管理员执行恢复出厂设置（也包括配置信息）。 状态备份和恢复 - 管理员可以对Defense4All状态进行快照，将备份保存在其他位置，然后恢复到原始或新的Defense4All位置。这允许克服某些逻辑错误和错误配置，以及承载Defense4All的机器的永久故障。要快照Defense4All状态，请执行以下操作： 停顿（关闭）Defense4All，导致当前状态刷新到稳定的存储）。避免在恢复时执行任何配置更改，避免新的状态更改。获取Defense4All DB - “DF”的Cassandra快照：有关备份还原准则，请参阅 http://www.datastax.com/docs/1.0/operations/backup_restore。将快照文件复制到所需的存储归档。要将Defense4All备份恢复到目标计算机，请执行以下操作： 在目标计算机中恢复所需的已保存快照（与备份相同或不同）。有关Cassandra备份 - 恢复指南，请参阅http://www.datastax.com/docs/1.0/operations/ backup_restore。在该机器上启动Cassandra。在该机器上启动Defense4All。维护和升级关于升级的一个关键问题是数据的格式是否改变。未来版本的Defense4All将必须通过以下两种方式之一处理更改的数据格式： 作为升级过程的一部分，自动升级存储库中的状态格式需要Defense4All重置，然后删除所有现有存储库表，然后创建新格式的表。有关升级的另一个关键问题是与外部实体的兼容性：OFC，NetNodes和AMS。升级版本中的StatsCollectionRep，DvsnRep和AmsRep必须能够处理其外部实体，无论是从头开始还是从先前设置的配置和在运行时获得的数据。 Defense4All升级过程包括： 备份它的状态或者出厂重置它停止它升级任何外部实体升级它（Re）启动它要降级Defense4All： 出厂复位停下来降级任何外部实体降级它在升级之前恢复其备份状态启动它因为在这个版本Defense4All没有集群，集群滚动升级不适用这里。 新术语和概念AMS - 攻击减轻系统，用于检测，减轻和报告网络攻击。例如，Radware的DefensePro是一种能够检测，减轻和报告大量网络攻击的AMS。攻击 - 怀疑或检测到PN上的DDoS或其他网络攻击。攻击可以是网络链路，目的地址，协议或第4层端口的任何组合。Defense4All维持攻击生命周期，其中它试图根据每个主题PN的规范来减轻攻击。检测 - 检测到监控的交通异常的指示。检测具有到期时间，并且可以更新。缓解 - 正在执行以缓解给定攻击的活动。在本版本中，所有攻击都通过将攻击流量转移到DefensePro来缓解，并将干净的流量重新注入VTN。NetNode - 模拟交换机或类似的网络设备，以及其流量端口，受保护的链路和与AMS的连接。NetNode指定一个或多个PN的业务通常流过（如果不被重定向）和/或AMS连接到的感兴趣的网络位置。在和平时间Defense4All通过该PN的业务流在每个网络中设置PN的计数器。攻击Defense4All选择一个或多个连接到引入的NetNodes的AMS，并将攻击/所有流量重定向到连接到这些NetNode的AMS。OFC - 支持OpenFlow网络编程的SDN控制器（OFC代表OpenFlow控制器）。OpenDaylight控制器为支持OpenFlow的网络设备和其他网络设备提供这种风格。受保护网络（PN） - 这是具有给定保护规范的用户定义的受保护网络元素。网络由两部分的任意组合指定：1）网络地址范围（并且可选地仅协议L4端口），以及2）指定业务流经过的网络链路。两个部分（但不是两者）中的任一个可以是未指定的。在版本1.0中，仅实现了第二部分。保护规范指示与对主题PN的攻击的检测和缓解相关的属性的范围。受保护对象（PO​​） - 在Defense4All中，受保护网络（PN）称为受保护对象（PO​​）。保护链路 - 交换机中的一组入口 - 出口端口。Defense4All通过要求在网络拓扑中设置为“bump-in-the-wire”的sdn-native开关，避免学习所有路由表。Defense4All程序使未攻击的流量进入其中一个入口 - 出口对端口以退出另一个。sdn-hybrid和sdn- native - 有两种类型的SDN交换机：sdn-hybrid，它支持SDN和传统路由，sdn-native支持仅SDN路由。在sdn混合交换机上计数流量可以通过对具有期望的流量选择标准的流条目进行编程来完成，并且动作被发送到正常，意味着继续传统路由。对sdn本机交换机上的流量计数需要显式路由操作（将流量发送到哪个输出端口）。Defense4All通过需要一个sdn本地交换机来避免学习所有路由表，该交换机或多或少是相对于流量路由的线路，意味着进入端口1的业务通常退出端口2，进入端口3的业务通常退出端口4，反之亦然。这样的开关允许简单地对流条目进行编程，以便计数流量或将流量转移到附接的AMS /从附接的AMS转移流量。当Defense4All对包含端口1的选择标准的流量计数流条目进行编程时，其操作将输出到端口2，类似于3到4.此限制预计在将来的版本中取消。另请参阅受保护的链接项。流量楼层 - 在给定的NetNode上Defense4All程序的一组流条目。不同的PN具有它们自己的业务层用于和平时间攻击检测，以及用于攻击缓解的业务重定向。攻击流量楼层包含优先级高于该PN的所有先前设置的攻击缓解流量楼层的流条目，以及平时流量楼层（其包含仅用于计数PN流量以便学习行为和异常的流条目）。攻击可以完全或部分地删除早期的攻击（例如TCP上的TCP端口80通过TCP或反之亦然）或不连接（例如TCP和UDP）。统计收集来自所有交通楼层：平时和攻击。基于SDN的检测器将所有统计信息汇总到总速率，确定攻击是否仍然开启。被削减的和平时间计数的交通可以显示零利率，并且计数由更高优先权的楼层计数器补充。流量端口 - 北Vexternal，流量通过该端口进入PN的VTN。ProtectedLink是NetNode中的Vbridge的名称。其他信息安全和隐私Defense4All REST API目前不检查凭据。它也不根据允许或限制某些REST API的使用来定义用户角色。 兼容性这个Defense4All版本（1.0.7）与ODC 1.0兼容。AmsRep的参考实现是通过Radware的DefensePro版本：硬件版本ODS-VL，软件版本6.03,6.07和6.09。 性能和可伸缩性信息TBD。 参考资料[ODC] 返回Defense4All用户指南页面 隐私政策 关于OpenDaylight项目 免责声明 的页面","tags":[{"name":"SDN","slug":"SDN","permalink":"https://nachtz.github.io/tags/SDN/"}]},{"title":"SDN收藏夹","date":"2017-01-08T05:24:31.000Z","path":"2017/01/08/SDN_Link/","text":"SDN收藏夹 OpenDayLight操作ODL与mininetODL控制器集群简单入门(13年12月) OpenDayLight编程开发Linux编译环境搭建windows下环境搭建(该文作者系列文章)官方maven编译安装教程注意maven编译的时候可能需要使用代理来访问远端maven仓库控制器上bundle的二次开发开发一个bundle(已经过期无法按照原文步骤演示了，但是可以看看。原文)利用北向接口NBI来写一个统计程序官方开发控制器app文档YANG模型 OpenDayLight 源码与APIODL 氢版本数据通讯版本源码解读defenseAll (已被odl官方存档弃用)控制器mdsal组件列表ODL beryllium版本API，已过期ODL boron版本API，目前最新(1/6/2017)官方Git 其他sdn架构ovs模块划分ovs源码分析系列ODL用户邮件(感觉有用，但是不知道怎么用)ODL 负载均衡演示(已过期)ODL安全措施，没啥用","tags":[{"name":"SDN","slug":"SDN","permalink":"https://nachtz.github.io/tags/SDN/"}]},{"title":"在OpenDayLight控制器上开发Bundle","date":"2017-01-08T05:24:31.000Z","path":"2017/01/08/SDN_opendaylight_dev_bundle/","text":"在OpenDayLight控制器上开发Bundle odl远端仓库把startup project删除了。这个教程已经不再适用了。基于OpendayLight官网上的这篇文档翻译修改而来：Developing Apps on the OpenDaylight controller 本文档适用于boron版本。其他版本不一定适用。 综述本文档旨在指导如何在ODL控制器上开发应用。本文档包含以下内容： 创建一个简单的示例程序Hello World； 启动ODL控制器； 在Hello World测试简单的Remote Procedure Call(RPC)。 基础环境本文档需要以下基础开发环境： Maven 3.1.1 或更新的版本 JDK 7/8 合适的Maven settings.xml。可以通过一下途径获得默认的OpenDaylight settings.xml 1cp -n ~/.m2/settings.xml&#123;,.orig&#125; ; \\wget -q -O - https://raw.githubusercontent.com/opendaylight/odlparent/stable/boron/settings.xml &gt; ~/.m2/settings.xml 在除Linux和Mac OS X以外的环境中，你需要修改上诉命令中maven的本地仓库地址~/.m2/repository 构建一个Example模块 按以下步骤构建： 从Maven远端仓库中拉取一个初始工程。（第一次拉取的时候需要一定的时间） 123mvn archetype:generate -DarchetypeGroupId=org.opendaylight.controller -DarchetypeArtifactId=opendaylight-startup-archetype \\-DarchetypeRepository=https://nexus.opendaylight.org/content/repositories/public/ \\-DarchetypeCatalog=https://nexus.opendaylight.org/content/repositories/public/archetype-catalog.xml 在国内，由于墙的缘故，你可能需要设置代理才能较快的下载工程。设置代理的参数如下： 1-DsocksProxyHost=YourProxyHost -DsocksProxyPort=YourProxyPort 此外你还可以使用多线程编译，跳过生成文档，跳过测试来加快速度： 1-T 1C -D maven.javadoc.skip=true -DskipTests 使用如下值来初始化工程： 123456Define value for property 'groupId': : org.opendaylight.exampleDefine value for property 'artifactId': : exampleDefine value for property 'version': 1.0-SNAPSHOT: : 1.0.0-SNAPSHOTDefine value for property 'package': org.opendaylight.example: :Define value for property 'classPrefix': : $&#123;artifactId.substring(0,1).toUpperCase()&#125;$&#123;artifactId.substring(1)&#125;Define value for property 'copyright': : Copyright (c) 2015 Yoyodyne, Inc. 其中，version,package,classPrefix都会默认填写，直接回车就行。 完成步骤1,2后，可以看到一个example文件夹。可以看到如下目录结构。 123456789$&#123;artifactId&#125;/example/cd example/api/artifacts/features/impl/karaf/pom.xml 构建示例工程。 注意，这个可能需要耗费一定的时间，你可以使用1中提到的maven参数来提升编译速度。 1mvn clean install 启动ODL控制器。 123cd karaf/target/assembly/binls./karaf 等待直至启动完毕出现以下命令行。可能需要等一段时间，这个时间和你电脑配置有关。 1opendaylight-user@root&gt; 查看日志，确认example模块被正常加载。 1log:display | grep Example 关闭ODL控制器。 1shutdown -f 定义一个简单的`Hello World RPC 从maven远端仓库拉取初始工程。 123mvn archetype:generate -DarchetypeGroupId=org.opendaylight.controller -DarchetypeArtifactId=opendaylight-startup-archetype \\ -DarchetypeRepository=http://nexus.opendaylight.org/content/repositories/opendaylight.release/ \\ -DarchetypeCatalog=http://nexus.opendaylight.org/content/repositories/opendaylight.release/archetype-catalog.xml 这里需要注意，原文中使用的是snapshot，而使用snapshot会出现无法编译通过的问题。本文中使用release版本且目前的maven远端仓库release版本是boron。 使用如下值来初始化工程： 123456Define value for property 'groupId': : org.opendaylight.helloDefine value for property 'artifactId': : helloDefine value for property 'version': 1.0-SNAPSHOT: : 1.0.0-SNAPSHOTDefine value for property 'package': org.opendaylight.hello: :Define value for property 'classPrefix': : $&#123;artifactId.substring(0,1).toUpperCase()&#125;$&#123;artifactId.substring(1)&#125;Define value for property 'copyright': : Copyright (c) 2015 Yoyodyne, Inc. 其中，version,package,classPrefix都会默认填写，直接回车就行。 查看hello工程。 12345678cd hello/ls -1apiartifactsfeaturesimplkarafpom.xml 构建Hello工程。 1mvn clean install 同样，可以利用之前提到的参数来提升编译构建速度。 启动ODL控制器。 123cd karaf/target/assembly/binls./karaf 等待直至启动完毕出现以下命令行。可能需要等一段时间，这个时间和你电脑配置有关。 1opendaylight-user@root&gt; 查看日志，确认Hello模块被正常加载。 1log:display | grep Hello 关闭ODL控制器。 1shutdown -f 返回到Hello目录： 1cd ../../../../ 可以通过查看Hello模块的实现来了解7中的日志从何而来，模块实现源文件路径如下： 1impl/src/main/java/org/opendaylight/hello/impl/HelloProvider.java 可以使用HelloProvider.onSessionInitiate方法来添加自己的实现。 1234@Overridepublic void onSessionInitiated(ProviderContext session) &#123; LOG.info(\"HelloProvider Session Initiated\");&#125; 添加一个简单的HelloWorld RPC API 修改YANG文件。 1vi api/src/main/yang/hello.yang 修改为如下文件，通过修改该文件来定义hello-world RPC： 1234567891011121314151617181920 module hello &#123; yang-version 1; namespace \"urn:opendaylight:params:xml:ns:yang:hello\"; prefix \"hello\"; revision \"2015-01-05\" &#123; description \"Initial revision of hello model\"; &#125; rpc hello-world &#123; input &#123; leaf name &#123; type string; &#125; &#125; output &#123; leaf greating &#123; type string; &#125; &#125; &#125;&#125; 返回到hello/api目录并构建你的API: 12cd ../../../mvn clean install 实现HelloWorld RPC API 定义HelloService，该服务会被HelloWorldAPI调用。 1cd ../impl/src/main/java/org/opendaylight/hello/impl/ 创建HelloWorldImpl.java文件，添加如下代码： 1234567891011121314151617181920212223/** Copyright © 2016 Cisco Systems and others. All rights reserved.** This program and the accompanying materials are made available under the* terms of the Eclipse Public License v1.0 which accompanies this distribution,* and is available at http://www.eclipse.org/legal/epl-v10.html*/package org.opendaylight.hello.impl;import java.util.concurrent.Future;import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloService;import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloWorldInput;import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloWorldOutput;import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloWorldOutputBuilder;import org.opendaylight.yangtools.yang.common.RpcResult;import org.opendaylight.yangtools.yang.common.RpcResultBuilder;public class HelloWorldImpl implements HelloService &#123; @Override public Future&lt;RpcResult&lt;HelloWorldOutput&gt;&gt; helloWorld(HelloWorldInput input) &#123; HelloWorldOutputBuilder helloBuilder = new HelloWorldOutputBuilder(); helloBuilder.setGreating(\"Hello \" + input.getName()); return RpcResultBuilder.success(helloBuilder.build()).buildFuture(); &#125;&#125; 修改HelloProvider.java.注册在hello.yang中创建的RPC. 你可以自己添加自己想要的实现，或者直接按如下编写： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/* * Copyright © 2016 Cisco Systems and others. All rights reserved. * * This program and the accompanying materials are made available under the * terms of the Eclipse Public License v1.0 which accompanies this distribution, * and is available at http://www.eclipse.org/legal/epl-v10.html */package org.opendaylight.hello.impl;import org.opendaylight.controller.md.sal.binding.api.DataBroker;import org.opendaylight.controller.sal.binding.api.RpcProviderRegistry;import org.opendaylight.controller.sal.binding.api.BindingAwareBroker.RpcRegistration;import org.opendaylight.yang.gen.v1.urn.opendaylight.params.xml.ns.yang.hello.rev150105.HelloService;import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloProvider &#123; private static final Logger LOG = LoggerFactory.getLogger(HelloProvider.class); private final DataBroker dataBroker; private final RpcProviderRegistry rpcProviderRegistry; private RpcRegistration&lt;HelloService&gt; serviceRegistration; public HelloProvider(final DataBroker dataBroker, RpcProviderRegistry rpcProviderRegistry) &#123; this.dataBroker = dataBroker; this.rpcProviderRegistry = rpcProviderRegistry; &#125; /** * Method called when the blueprint container is created. */ public void init() &#123; serviceRegistration = rpcProviderRegistry.addRpcImplementation(HelloService.class, new HelloWorldImpl()); LOG.info(\"HelloProvider Session Initiated\"); &#125; /** * Method called when the blueprint container is destroyed. */ public void close() &#123; serviceRegistration.close(); LOG.info(\"HelloProvider Closed\"); &#125;&#125; &gt; 这边需要注意：文件开头的版权声明不能去掉，否则无法通过Maven构建。此外，官网上的源文件有问题。本文档的源文件至少通过了本地编译。 此外，需要在BluePrint中注册你的RPC API.修改如下： 12cd hello/impl/src/main/resources/org/opendaylight/blueprintvi impl-blueprint.xml 修改为如下。 12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!-- vi: set et smarttab sw=4 tabstop=4: --&gt;&lt;!--Copyright © 2016 Cisco Systems and others. All rights reserved.This program and the accompanying materials are made available under theterms of the Eclipse Public License v1.0 which accompanies this distribution,and is available at http://www.eclipse.org/legal/epl-v10.html--&gt;&lt;blueprint xmlns=\"http://www.osgi.org/xmlns/blueprint/v1.0.0\"xmlns:odl=\"http://opendaylight.org/xmlns/blueprint/v1.0.0\"odl:use-default-for-reference-types=\"true\"&gt; &lt;reference id=\"dataBroker\" interface=\"org.opendaylight.controller.md.sal.binding.api.DataBroker\" odl:type=\"default\" /&gt;&lt;reference id=\"rpcRegistry\" interface=\"org.opendaylight.controller.sal.binding.api.RpcProviderRegistry\" /&gt;&lt;bean id=\"provider\" class=\"org.opendaylight.hello.impl.HelloProvider\" init-method=\"init\" destroy-method=\"close\"&gt; &lt;argument ref=\"dataBroker\" /&gt; &lt;argument ref=\"rpcRegistry\" /&gt;&lt;/bean&gt;&lt;/blueprint&gt; &gt; 这个文档中添加了`rpcRegistry`。需要注意&lt;?xml&gt;前不能有空格。 然后回到hello/impl目录下编译。 1mvn clean install 回到hello目录下编译。 1mvn clean install 通过REST来测试hello-world RPC 有很多方式可以测试RPC, 比如以下两种。 通过HTTP使用ODL控制器自带的API Explorer 使用浏览器的REST 客户端 通过HTTP使用ODL控制器自带的API Explorer 使用浏览器进入 apidoc UI&lt;http://localhost:8181/apidoc/explorer/index.html&gt; 。 TIP: localhost是你ODL控制器的IP地址或者Hostname。 选择 12hello(2015-01-05) 选择 12POST /operations/hello:hello-world 在框内填写如下值 12&#123;\"hello:input\": &#123; \"name\":\"Your Name\"&#125;&#125; 点击按钮. 输入 username 和 password, 默认是admin/admin. 返回的Response body应该为： 123456&#123; \"output\": &#123; \"greating\": \"Hello Your Name\" &#125;&#125; 使用浏览器的REST 客户端 可以使用火狐浏览器的 RESTClient或者Chrome的Restlet Client。 1POST: http://192.168.1.43:8181/restconf/operations/hello:hello-world Header: ``` application/json ``` Body: {&quot;input&quot;: { &quot;name&quot;: &quot;Andrew&quot; } } TroubleshootingIf you get a response code 501 while attempting to POST/operations/hello:hello-world, check the file: HelloProvider.java andmake sure the helloService member is being set. By not invoking“session.addRpcImplementation()” the REST API will be unable to map/operations/hello:hello-world url to HelloWorldImpl. 这个应该碰不到了。所以就不翻译了。","tags":[{"name":"SDN","slug":"SDN","permalink":"https://nachtz.github.io/tags/SDN/"}]},{"title":"SDN综述","date":"2016-12-18T05:24:31.000Z","path":"2016/12/18/SDN_conclusion/","text":"论文^1 思想利用分层思想，将数据与控制分离。控制层有逻辑中心化和可编程控制器。数据层有dump 交换机，只负责数据的转发，课快速处理匹配数据包，适应流量日益增长的需求。两层之间采用开放统一的接口（比如openflow）交互。控制器通过接口下发规则，交换机按照规则执行工作。 体系结构架构^1SDN由北向南分为三个接口：数据平面、控制平面、和应用平面。数据平面与控制平面之间利用用SDN控制数据平面接口(control-data-plane interface，简称CDPI)进行通信。CDPI有统一的标准，目前是 OpenFlow协议。控制平面与应用平面之间采用SDN北向接口(northbound interface，简称NBI)。NBI可以依照用于实际需求定制。 数据平面由交换机等网络元素链接。可以将至视为传统的数据链路，负责网络之间的数据交互，并接受上层的控制。控制平面是中间件，通过CDPI驱动来监控管理数据平面中的网络元素的行为，并通过北向接口来接收应用层的命令。应用平面包含各类基于SDN的网络应用，用户无需关心底层实现，就可以通过简单编程实现应用的快速部署。网络抽象特性允许用户可以根据需求选择不同的网络操作系统，而并不影响物理设备的正常运行。 不同方向NFV(Network Function Virtulizaiton),是指将传统的网络功能虚拟化，使之独立于硬件。在相同的硬件上，可以运行不同的网络功能。从而减少专属设备的硬件成本。NVF用了资源虚拟化的方式，在硬件设备中建立一个网络虚拟层，负责将硬件资源虚拟化，形成虚拟计算资源、虚拟存储资源和虚拟网络资源等，运营商通过软件来管理这些虚拟资源．由于采用的是通用硬件设备，NFV降低了设备成本，减少了能耗，缩短了新网络服务的部署周期，从而适应网络运营商的发展需求．在接口设计方面，NFV既可以基于非OpenFlow协议，又能与OpenFlow协同工作，同时还支持ForCES等多种传统接口标准化协议，以便适应网络运营商对设备的不同需求，并与ONF的SDN保持相对独立的发展． OpenDaylight是一套以社区为主导的开源框架,旨在推动创新实施以及SDN透明化。考虑到兼容性问题，OpenDaylight继承了SDN架构形式，同时又结合了NFV的特点．架构共分为3个层次，分别是网络应用与业务流程(即应用层)、控制平台(即控制层)和物理与虚拟网络设备(即数据层)．OpenDaylight的控制平台直接由自带的Java虚拟机实现．针对不同的网络任务，控制器自身携带了一系列可插入模块，并兼容第三方模块以增强SDN的功能．与ONF的SDN架构最大的不同在于：OpenDaylight控制器的南向接口除了支持OpenFlow协议之外，还支持NETCONF等配置协议和BGPt24等路由协议，并支持生产厂商的专有协议(如思科的OnePK协议)．为了能够处理不同的标准协议，OpenDaylight增加了服务抽象层SAL，它负责将不同的底层协议标准转换成OpenDaylight控制层所理解的请求服务，保持了底层协议的透明性，并提高了整体架构的可扩展性． 开放式接口与协议设计SDN接口中，以控制器为中心，南向与数据层通信，北向与应用层通信。并支持多控制器，在东西向进行多控制器通信。作为数据与控制分离的核心，南向接口是目前相对研究比较多的点。比如ONF的CDPI,采用openflow。Openflow基于流的概念来匹配规则，交换机通过维护流表（Flow table）来支持openflow，按流表进行数据转发。流表的建立，维护及下发由控制器进行。 对于北向的研究，有ONF的NBI，OpenDaylight的REST等。这一方面的研究在于如何实现统一的北向接口标准。 东西向接口为负载均衡和性能提升提供保障。 数据层关键技术在SDN中，数据层与控制层分离，控制策略部分被交给控制器负责，数据层上的研究主要集中在交换机设计和转发规则。 交换机设计问题SDN交换机位于数据层面。用来负责数据流转发。可以使用硬件和软件两种方式进行转发。硬件转发速度快，成本低，功耗小，但是灵活性不够。对此，Bosshart等人[^32]提出了针对数据平面转发的RMT模型。允许在流水线阶段支持任意宽度和深度的流表。 允许随意替换或增加域定义； 允许指定流表的数量、拓扑、宽度和深度，仅仅受限于芯片的整体资源(如芯片内存大小等)； 允许创建新动作； 可以随意将数据包放到不同的队列中，并指定发送端口。 此外，FlowAdapter是另一种利用硬件灵活处理的技术。FlowAdapter采用三层结构。最上层是可以通过更新来支持任何新协议的软件数据平面，底层是相对固定但转发效率高的硬件数据平面，位于中部的FlowAdapter层负责软件数据平面和硬件数据平面之间的通信．当控制器下发规则时，软件数据平面将存储这些规则，形成M个阶段的流表．由于这些规则相对灵活，不能全部由交换机直接转化成相应转发动作，而硬件数据平面可以实现规则的高速匹配转发．因此可利用中间层FlowAdapter将两个数据平面中的规则进行无缝转换，即，将相对灵活的M阶段的流表转换成能够被硬件所识别的Ⅳ阶段的流表．为了达到转换目的，FlowAdapter首先检查软件数据平面的全部规则，然后根据完整的规则将M阶段的流表转换成l阶段流表，最后再将1阶段流表转换成Ⅳ阶段流表发送给硬件数据平面．．另外，FlowAdapter相对控制器完全透明，对FlowAdapter交换机的更新不会影响控制器的正常运行． 与硬件设计交换机的观点不同，软件处理速度虽然低于硬件。但是软件方式可以最大限度提升规则灵活性。同时避免硬件受制于自身资源限制导致的流表大小受限，无法有效处理突发流的问题。同时软件也可以采用专用的NP(Network Processor)来替换CPU. 转发规则的研究如果网络节点失效，或者网络流量需要负载转移等情况，都会引发转发规则的变换。SDN采用高抽象层次的管理方式统一更新规则，防止出现规则更新不一致和规则延迟的现象。一般采用两阶段提交方式更新规则[^40]： 第一阶段：规则需要更新，控制器询问每一个交换机是否处理完对应旧规则的流。并对处理完成的所有交换机进行规则更新。第二阶段：当所有交换机都更新完毕后，才算完成更新，否则取消该更新操作。这种方法需要等待旧规则的数据包处理完毕后才能处理新规则的数据包，会导致规则空间被占用的问题。这个时候可以采用增量式一致更新：，该算法将规则更新分成多轮进行每一轮都采用二阶段提交方式更新一个子集，这样可以节省规则空间，达到更新时间与规则空间的折中。 控制层关键技术控制器是控制层核心组件。通过控制器，用户可以逻辑上集中控制交换机，实现数据快速转发，安全便捷管理网络，提神网络整体性能。 控制器设计问题控制器基本功能是为科研人员提供可用的编程平台，最早且广泛使用的控制器平台是NOX。提供了一系列基本接口，用户通过NOX对全局网络信息进行获取，控制与管理。NOX的问题在于，随着SDN网络规模的扩展,单一结构集中控制的控制器处理能力受限，扩展困难，只能应用于小型企业网络或者科研人员进行仿真。网络中有两种方式扩展，第一是提升控制器性能，比如NOX-MT，第二种是采用多控制器方式提升整体控制器的能力。NOX-MT是具有多线程处理能力的NOX控制器，NOX-MT不改变NOX控制器的基本结构，而是利用传统并行技术提升性能。对于大规模网络，需要采用多控制器进行处理。分布式控制器有两种方式进行扩展，扁平控制方式和层次控制方式。．对于扁平控制方式（比如ONIX,HyperFlow），所有控制器被放置在不相交的区域里，分别管理各自的网络．各控制器间的地位相等，并通过东西向接口进行通信．对于层次控制方式(Kandoo)，控制器之间具有垂直管理的功能．也就是说，局部控制器负责各自的网络，全局控制器负责局部控制器，控制器之间的交互可通过全局控制器来完成． SDN网络操作系统应该具有实时运行开发应用的能力，力求开发与执行的平衡。NOX采用Python或c++. 二者在开发效率和执行效率上各有偏重。科研人员致力于开发通用平台，Beacon就是一个基于Java的通用平台。它向用户提供了一系列相关的库与接口用于开发，并提供运行时模块化的功能，使其在保证性能的情况下具有了实时运行的能力，实现了开发与执行两者之间的平衡。 接口语言传统的低级配置接口，比如用c++编写的接口，抽象程度低，不能大幅减少使用成本， 就有团队致力于开发网络配置语言,旨在搭建具有优化性能的通用北向接口。比如Nettle,McNettle(Nettle多核版)，采用了函数响应式编程（FPR）方式。Maple则对接口语言进一步抽象，允许用户使用自定义抽象策略。为了能够高效地将抽象策略分解成一系列规则，并下发到相应的分布式交换机上，Maple不但采用了高效的多核调度器，最关键的是，它采用了跟踪运行时优化器(tracing runtime optimizer)来优化性能．该优化器一方面通过记录可重用的策略，将负载尽可能地转移到交换机来处理．另一方面，通过动态跟踪抽象策略与数据内容及环境的依赖性，使流表始终处于最新状态，从而确保抽象策略转成可用规则的效率。 此外还介绍了Frenetic等。 控制层特性研究控制层存在一致性，可用性和容错性等特性，但是三种特性无法同时满足，达到三者之间的平衡和整体的最优化，是这个方向上的重点。 一致性集中控制是SDN区别于其他网络架构的核心优势之一，通过集中控制，用户可以获取全局网络视图，并根据全网信息对网络进行统一设计与部署，理论上保证了网络配置的一致性问题．然而，分布式控制器仍然具有潜在的不一致性问题．由于不同控制器的设计对网络一致性要求有所不同，严格保证分布式状态全局统一的控制器，将无法保证网络性能；反之，如果控制器能够快速响应请求，下发策略，则无法保证全局状态一致性．性能无明显影响的情况下，保证状态一致性成为了SDN设计中的关键问题。并发策略同样会导致一致性问题。可以由控制层将策略形成规则，并按两阶段提交方式解决．为了避免数据层过多的参与，控制层可直接通过并发策略组合的方式来解决，并可利用细粒度锁(fine—grained locking)确保组合策略无冲突发生．HFT采用了层次策略方案，它将并发策略分解，组织成树的形式，树的每个节点都可独立形成转发规则．HFT首先对每个节点进行自定义冲突处理操作，这样，整个冲突处理过程就转化成利用自定义冲突处理规则逆向搜索树的过程，从而解决了并发策略一致性问题． 可用性规则备份可以提升网络的可用性（RuleBrieks）。控制器作为SDN的核心处理节点，需要处理来自交换机的大量请求，而过重的负载会影响SDN的可用性．利用分布式控制器可以平衡负载，提升SDN的整体性能．（ndoo，ElastiCon）.减少交换机的请求次数，可以提升控制层可用性。（DIFANE,DevoFlow） 容错性与传统的互联网类似，SDN同样面临着网络节点或链路失效的问题．然而，SDN控制器可以通过全网信息快速恢复失效节点，具有较强的容错能力．网络节点恢复收敛过程如图7所示： 当某台交换机失效时，其他交换机察觉出变化； 交换机将变化情况通知控制器； 控制器根据所掌握的信息，计算出需要恢复的规则； 将更新发送给数据平面中受到影响的网络元素； 数据平面中受影响的元素分别更新流表信息． 从链路恢复过程可以看出：在SDN架构中，失效信息一般不是通过洪泛方式通知全网，而是直接发送给控制层，并由控制器来做恢复决策，因而不易出现路由振荡的现象．如果是交换机和控制器之间的链接失效，导致无法通信，则收敛过程相对困难．可以采用传统网络的IGP(如OSPF协议)通信，并通过洪泛方式恢复，也可以采用故障转移(failover)方式，同样能够缓解链路失效收敛时间问题．通过在交换机上安装用于验证拓扑连接性的静态转发规则，可以更好地实现网络故障的快速收敛．控制层也提供了一种高级容错语言FatTire. SDN应用研究企业与校园网早期SDN研究主要场景。在第二代中国教育和科研计算机网中，利用4over6技术和SDN网络虚拟化思想进行v4到v6的过渡。 数据中心与云数据中心需求带宽高，设备繁多，高度集中，在此部署SDN也有严峻的考验。早期的实例是基于NOX的SDN网络。在合理运用带宽方面的实践有OpenFlow,DevoFlow,zUpdate等。在节能方面，利用SDN掌控全局，实时关闭不必要的设备以进行节能，能够节省约一半的能耗。同时也能进行负载均衡，避免资源浪费。 广域网Google B4系统，微软SWAN系统，都基于SDN架构，大幅提升了链路利用率。其中SWAN系统主要基于传统设备，利于普及和升级。 无线网络OpenRoads, Odin,OpenRadio,SoftRAN等。 SDN未来方向SDN可扩展性研究SDN规模部署和跨域通信传统网络与SDN共存问题研究SDN在数据中心的应用研究借鉴SDN思想融合IPv6过渡机制SDN与其他新型网络架构融合SDN网络安全控制器mdsal组件列表ODL beryllium版本API，已过期ODL boron版本API，目前最新(1/6/2017)官方Git 其他sdn架构ovs模块划分ovs源码分析系列ODL用户邮件(感觉有用，但是不知道怎么用)ODL 负载均衡演示(已过期)ODL安全措施，没啥用","tags":[{"name":"SDN","slug":"SDN","permalink":"https://nachtz.github.io/tags/SDN/"}]},{"title":"Smarking Algorithm Contest 3","date":"2016-11-06T06:37:31.000Z","path":"2016/11/06/Smarking Algorithm Contest 3/","text":"1. 453. Minimum Moves to Equal Array ElementsGiven a non-empty integer array of size n, find the minimum number of moves required to make all array elements equal, where a move is incrementing n - 1 elements by 1.Ex:12345678910Input:[1,2,3]Output:3Explanation:Only three moves are needed (remember each move increments two elements):[1,2,3] =&gt; [2,3,3] =&gt; [3,4,3] =&gt; [4,4,4] 给一个长度为n的非空数组，将这个数组中的其中n-1个元素都+1，称为一次操作。求出将这个数组所有元素都变为相同大小的操作的次数。解法：12345678910111213141516func minMoves(nums []int) int &#123; if len(nums) &lt;= 1&#123; return 0 &#125; sum,min,max := nums[0],nums[0],nums[0] for i:=1;i&lt;len(nums);i++&#123; sum += nums[i] if min &gt; nums[i]&#123; min = nums[i] &#125; if max &lt; nums[i]&#123; max = nums[i] &#125; &#125; return sum - len(nums)*min&#125; 2. 447. Number of BoomerangsGiven n points in the plane that are all pairwise distinct, a “boomerang” is a tuple of points (i, j, k) such that the distance between i and j equals the distance between i and k (the order of the tuple matters). Find the number of boomerangs. You may assume that n will be at most 500 and coordinates of points are all in the range [-10000, 10000] (inclusive).Ex:12345678Input:[[0,0],[1,0],[2,0]]Output:2Explanation:The two boomerangs are [[1,0],[0,0],[2,0]] and [[1,0],[2,0],[0,0]] 给定平面内的坐标。求出这些坐标中，一个点到另外两个点距离相同的组合。这题只要求出每个坐标到其他坐标的距离。然后再遍历就行了。 1234567891011121314151617181920212223242526272829303132func pow(t int) int&#123; return t*t&#125;func numberOfBoomerangs(points [][]int) int &#123; if len(points) &lt;3&#123; return 0 &#125; dis := make([][]int,len(points)) for i:=0;i&lt;len(points);i++&#123; dis[i] = make([]int,len(points)) &#125; for i:=0;i&lt;len(points);i++&#123; for j:=i+1;j&lt;len(points);j++&#123; t := pow(points[i][0] - points[j][0])+pow(points[i][1] - points[j][1]) dis[i][j],dis[j][i] = t,t &#125; &#125; count := 0 for i:=0;i&lt;len(points);i++&#123; for j:=0;j&lt;len(points);j++&#123; if j == i&#123; continue &#125; for k := j+1;k&lt;len(points);k++&#123; if dis[i][j] == dis[i][k]&#123; count +=2 &#125; &#125; &#125; &#125; return count&#125; 3. 452. Minimum Number of Arrows to Burst BalloonsThere are a number of spherical balloons spread in two-dimensional space. For each balloon, provided input is the start and end coordinates of the horizontal diameter. Since it’s horizontal, y-coordinates don’t matter and hence the x-coordinates of start and end of the diameter suffice. Start is always smaller than end. There will be at most 104 balloons. An arrow can be shot up exactly vertically from different points along the x-axis. A balloon with xstart and xend bursts by an arrow shot at x if xstart ≤ x ≤ xend. There is no limit to the number of arrows that can be shot. An arrow once shot keeps travelling up infinitely. The problem is to find the minimum number of arrows that must be shot to burst all balloons.Ex:12345678Input:[[10,16], [2,8], [1,6], [7,12]]Output:2Explanation:One way is to shoot one arrow for example at x = 6 (bursting the balloons [2,8] and [1,6]) and another arrow at x = 11 (bursting the other two balloons). 这题把一堆乱七八糟的背景剥开后，题目实际上是这样的：给定一组区间，然后要你给出长度最小的一组数，这组数中所有的点都在区间内而且没有区间被遗漏。用贪心算法就可以做。将区间按起点从小到大排列。然后每一次都选一个点，能够尽量的覆盖到最多的区间。直到不能覆盖为止。依次取点，直到区间都有点落在上面。1234567891011121314151617181920212223242526272829303132333435363738394041type ranges [][]int func(r ranges)Len() int&#123; return len(r)&#125;func(r ranges)Less(i,j int)bool&#123; if r[i][0] != r[j][0]&#123; return r[i][0]&lt;r[j][0] &#125; return r[i][1]&lt;r[j][1]&#125;func (r ranges)Swap(i,j int)&#123; r[i][0],r[j][0] = r[j][0],r[i][0] r[j][1],r[i][1] = r[i][1],r[j][1]&#125;func findMinArrowShots(points [][]int) int &#123; p := ranges(points) sort.Sort(p) count := 0 for i:=0;i&lt;len(p);i++&#123; count ++ j := i+1 at := p[i][1] for j = i+1;j&lt;len(p) ;j++&#123; if p[j][0]&gt;at&#123; i = j-1 break &#125; if p[j][1] &lt; at&#123; at = p[j][1] &#125; &#125; if j == len(p)&#123; break &#125; &#125; return count&#125; 4. 446. Arithmetic Slices II - SubsequenceA zero-indexed array A consisting of N numbers is given. A subsequence slice of that array is any sequence of integers (P0, P1, …, Pk) such that 0 ≤ P0 &lt; P1 &lt; … &lt; Pk &lt; N. A subsequence slice (P0, P1, …, Pk) of array A is called arithmetic if the sequence A[P0], A[P1], …, A[Pk-1], A[Pk] is arithmetic. In particular, this means that k ≥ 2. The function should return the number of arithmetic subsequence slices in the array A. Ex:12345678910111213Input: [2, 4, 6, 8, 10]Output: 7Explanation:All arithmetic subsequence slices are:[2,4,6][4,6,8][6,8,10][2,4,6,8][4,6,8,10][2,4,6,8,10][2,6,10] 这题试了下DFS会超时，用DP做会MLE。最后没做出来。给个别人的代码：123456789101112131415161718192021222324class Solution(object): def numberOfArithmeticSlices(self, A): \"\"\" :type A: List[int] :rtype: int \"\"\" ans=0 dp = [] for i in range(len(A)): a=A[i] dp.append(&#123;&#125;) for j in range(i): b=A[j] d=a-b if d in dp[j]: v=1+dp[j][d] else: v=1 if d in dp[i]: dp[i][d]=dp[i][d]+v else: dp[i][d]=v ans += sum([dp[i][x] for x in dp[i]]) - i return ans","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"Smarking Algorithm Contest 2","date":"2016-10-30T04:21:31.000Z","path":"2016/10/30/Smarking Algorithm Contest 2/","text":"435. Non-overlapping IntervalsGiven a collection of intervals, find the minimum number of intervals you need to remove to make the rest of the intervals non-overlapping. Note: You may assume the interval’s end point is always bigger than its start point. Intervals like [1,2] and [2,3] have borders “touching” but they don’t overlap each other. 给定一组区间，你可以移除一些区间让这组区间互不重叠。 做法是： 首先将区间按照起点大小排序。 将区间中所有完全覆盖其他区间的区间移除掉。 在剩下的区间中，如果有区间，和它之前的区间有重叠，就移除它。 代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859type arrI []Intervalfunc (a arrI)Len() int&#123; return len(a)&#125;func (a arrI)Less(i,j int) bool&#123; if a[i].Start!=a[j].Start&#123; return a[i].Start&lt;a[j].Start &#125; return a[i].End&gt;=a[j].End&#125;func (a arrI)Swap(i,j int)&#123; a[i],a[j] = a[j],a[i]&#125;func eraseOverlapIntervals(intervals []Interval) int &#123; if len(intervals) &lt;= 1&#123; return 0 &#125; tmp := arrI(intervals) sort.Sort(tmp) res := tmp[0] count :=0 ret := []Interval&#123;&#125; for i:=0;i&lt;len(tmp);i++&#123; flag := false if len(ret)&gt;0 &amp;&amp; tmp[i].Start &lt;= ret[len(ret)-1].Start&#123; flag = true count ++ &#125;else&#123; for j:=i+1;j&lt;len(tmp);j++&#123; if tmp[i].End &lt;= tmp[j].Start&#123; break &#125; if tmp[i].End &gt;= tmp[j].End&#123; flag = true count ++ break &#125; &#125; &#125; if !flag&#123; ret = append(ret,tmp[i]) &#125; &#125; if len(ret) == 0&#123; return count &#125; res =ret[0] for i:=1;i&lt;len(ret);i++&#123; if ret[i].Start &gt;= res.End&#123; res = ret[i] &#125;else&#123; count ++ &#125; &#125; return count&#125; 436. Find Right IntervalGiven a set of intervals, for each of the interval i, check if there exists an interval j whose start point is bigger than or equal to the end point of the interval i, which can be called that j is on the “right” of i. For any interval i, you need to store the minimum interval j’s index, which means that the interval j has the minimum start point to build the “right” relationship for interval i. If the interval j doesn’t exist, store -1 for the interval i. Finally, you need output the stored value of each interval as an array. Note: You may assume the interval’s end point is always bigger than its start point. You may assume none of these intervals have the same start point.给定一组区间，对于每一个区间，如果有其他区间的起点大于等于这个区间的终点，那么就称这个区间有右区间。找出最近的右区间的下标。没有右区间则该区间的最小右区间为-1。 这题直接用o(n*n)的算法就能过。即一个个找右区间。 123456789101112131415161718192021func findRightInterval(intervals []Interval) []int &#123; ret := make([]int,len(intervals)) for i:=0;i&lt;len(intervals);i++&#123; min := i for j:=0;j&lt;len(intervals);j++&#123; if j == i&#123; continue &#125; if intervals[j].Start &gt;= intervals[i].End&#123; if min == i || intervals[j].Start &lt; intervals[min].Start&#123; min = j &#125; &#125; &#125; if min == i&#123; min = -1 &#125; ret[i] = min &#125; return ret&#125; 441. Arranging CoinsYou have a total of n coins that you want to form in a staircase shape, where every k-th row must have exactly k coins. Given n, find the total number of full staircase rows that can be formed. n is a non-negative integer and fits within the range of a 32-bit signed integer. 水题，没啥好说的。12345678func arrangeCoins(n int) int &#123; idx :=1; for (n&gt;=idx)&#123; n -=idx idx ++ &#125; return idx-1&#125; 444. Sequence ReconstructionCheck whether the original sequence org can be uniquely reconstructed from the sequences in seqs. The org sequence is a permutation of the integers from 1 to n, with 1 ≤ n ≤ 10^4. Reconstruction means building a shortest common supersequence of the sequences in seqs (i.e., a shortest sequence so that all sequences in seqs are subsequences of it). Determine whether there is only one sequence that can be reconstructed from seqs and it is the org sequence. link没做出来，贴个别人的代码。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960class Solution &#123;public: bool sequenceReconstruction(vector&lt;int&gt;&amp; org, vector&lt;vector&lt;int&gt;&gt;&amp; seqs) &#123; int n = org.size(); vector&lt;int&gt; to(n), in(n); vector&lt;bool&gt; vis(n); vector&lt;vector&lt;int&gt;&gt; adj(n); int k = 0; for (auto &amp;x : org) &#123; x--; to[x] = k++; &#125; for (auto &amp;vec : seqs) &#123; for (auto &amp;c : vec) &#123; c--; if (c &lt; 0 || c &gt;= n) &#123; return false; &#125; vis[to[c]] = true; &#125; for (int i = 1; i &lt; vec.size(); i++) &#123; auto x = to[vec[i - 1]], y = to[vec[i]]; adj[x].push_back(y); in[y]++; if (x &gt; y) &#123; return false; &#125; &#125; &#125; queue&lt;int&gt; q; for (int i = 0; i &lt; n; i++) &#123; if (!vis[i]) &#123; return false; &#125; if (!in[i]) &#123; q.push(i); &#125; &#125; vector&lt;int&gt; sorted; while (!q.empty()) &#123; if (q.size() &gt; 1) &#123; return false; &#125; auto s = q.front(); q.pop(); sorted.push_back(s); for (auto v : adj[s]) &#123; if (!--in[v]) &#123; q.push(v); &#125; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; if (i != sorted[i]) &#123; return false; &#125; &#125; return true; &#125;&#125;;","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"Leetcode第十周周赛Smarking Algorithm Contest","date":"2016-10-23T06:37:31.000Z","path":"2016/10/23/leetcode_weekly_contest10/","text":"437. Path Sum IIIYou are given a binary tree in which each node contains an integer value. Find the number of paths that sum to a given value. The path does not need to start or end at the root or a leaf, but it must go downwards (traveling only from parent nodes to child nodes). The tree has no more than 1,000 nodes and the values are in the range -1,000,000 to 1,000,000.123456789101112131415root = [10,5,-3,3,2,null,11,3,-2,null,1], sum = 8 10 / \\ 5 -3 / \\ \\ 3 2 11 / \\ \\3 -2 1Return 3. The paths that sum to 8 are:1. 5 -&gt; 32. 5 -&gt; 2 -&gt; 13. -3 -&gt; 11 给你个树，求出所有符合路径上的节点的值的和等于给定值这个条件的路径的个数。路径要求是自上而下，但是不要求从根出发，也不要求以叶子节点作为结尾。挂在这道题上面了。给个别人的解法：将路径分为两种走法，每个节点都有两种走法。第一种情况是以这个节点为起点，开始出发。第二种是继承之前的走法接着走下去。12345678910111213141516171819202122232425262728var res intfunc go2(root *TreeNode, need int)&#123; if root == nil&#123; return &#125; if need == 0&#123; res ++ &#125; if root.Left != nil&#123; go2(root.Left,need-root.Left.Val) &#125; if root.Right != nil&#123; go2(root.Right,need-root.Right.Val) &#125;&#125;func go1(root * TreeNode, need int)&#123; if root == nil&#123; return &#125; go2(root,need-root.Val) go1(root.Left,need) go1(root.Right,need)&#125;func pathSum(root *TreeNode, sum int) int &#123; res = 0 go1(root, sum) return res&#125; 438. Find All Anagrams in a StringGiven a string s and a non-empty string p, find all the start indices of p’s anagrams in s. Strings consists of lowercase English letters only and the length of both strings s and p will not be larger than 20,100. The order of output does not matter.Example 1:123456789Input:s: \"cbaebabacd\" p: \"abc\"Output:[0, 6]Explanation:The substring with start index = 0 is \"cba\", which is an anagram of \"abc\".The substring with start index = 6 is \"bac\", which is an anagram of \"abc\". Example 2:12345678910Input:s: \"abab\" p: \"ab\"Output:[0, 1, 2]Explanation:The substring with start index = 0 is \"ab\", which is an anagram of \"ab\".The substring with start index = 1 is \"ba\", which is an anagram of \"ab\".The substring with start index = 2 is \"ab\", which is an anagram of \"ab\". 给定两个字符串s,p，求出p的所有变形（包括自己）在s中的起点。解法是统计p中的词频，然后统计s中i到i+len(p)中的字符串的词频。相比较，如果相等则说明命中了。123456789101112131415161718192021222324252627282930313233func check(a,b,c [26]int) bool&#123; for i:=0;i&lt;26;i++&#123; if a[i]-b[i] != c[i]&#123; return false &#125; &#125; return true&#125;func findAnagrams(s string, p string) []int &#123; if len(s)&lt;len(p)&#123; return []int&#123;&#125; &#125; ret := []int&#123;&#125; start, end, mark := [26]int&#123;&#125;,[26]int&#123;&#125;,[26]int&#123;&#125; for i:=0;i&lt;len(p);i++&#123; mark[p[i]-'a'] ++ &#125; for i:=0;i&lt;len(p);i++&#123; end[s[i]-'a'] ++ &#125; if check(end,start,mark)&#123; ret = append(ret,0) &#125; for i:=len(p);i&lt;len(s);i++&#123; start[s[i-len(p)]-'a'] ++ end[s[i]-'a']++ if check(end,start,mark)&#123; ret = append(ret,i-len(p)+1) &#125; &#125; return ret&#125; 439. Ternary Expression ParserGiven a string representing arbitrarily nested ternary expressions, calculate the result of the expression. You can always assume that the given expression is valid and only consists of digits 0-9, ?, :, T and F (T and F represent True and False respectively). Note: The length of the given string is ≤ 10000. Each number will contain only one digit. The conditional expressions group right-to-left (as usual in most languages). The condition will always be either T or F. That is, the condition will never be a digit. The result of the expression will always evaluate to either a digit 0-9, T or F.Example 1:123Input: \"T?2:3\"Output: \"2\"Explanation: If true, then result is 2; otherwise result is 3. Example 2:1234567891011121314Input: \"F?1:T?4:5\"Output: \"4\"Explanation: The conditional expressions group right-to-left. Using parenthesis, it is read/evaluated as: \"(F ? 1 : (T ? 4 : 5))\" \"(F ? 1 : (T ? 4 : 5))\" -&gt; \"(F ? 1 : 4)\" or -&gt; \"(T ? 4 : 5)\" -&gt; \"4\" -&gt; \"4\"``` 就是C语言中常见的`?:`语句。这题可以利用栈来做，也可以利用递归来做，应该也可以用正则表达式来做。下面是递归的做法： func parseTernary(e string) string { if e[0] != ‘T’ &amp;&amp; e[0]!=’F’{ return e } c1,c2,i := 0,0,1 for i=1;i","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"手写一个Pcap捕包工具及性能优化","date":"2016-10-19T04:37:31.000Z","path":"2016/10/19/dpdk_pcap/","text":"前言这是在项目上遇到的问题。因为项目的缘故，需要实现pcap捕包的功能，在使用后发现libpcap自身API使用比较复杂，就手写了一个API并尝试进行性能优化。部分代码在githuab上。pcapDumper pcap文件格式一个pcap文件的结构如下：(图片来自博客) 如上图，一个pcap文件，有两个部分组成，一个Pcap 头部，和一堆包。其中每一个包都有两个字段，分别是Packet Head和 Packet Data。它们的数据结构如下：123456789101112131415struct _pcap_file_header &#123; uint32_t magic; uint16_t version_major; uint16_t version_minor; int32_t thiszone; /* gmt to local correction */ uint32_t sigfigs; /* accuracy of timestamps */ uint32_t snaplen; /* max length saved portion of each pkt */ uint32_t linktype; /* data link type (LINKTYPE_*) */&#125;;struct _pcap_pkthdr &#123; struct _timeval ts; /* time stamp using 32 bits fields */ uint32_t caplen; /* length of portion present */ uint32_t len; /* length this packet (off wire) */&#125;; pcap_file_header存储着包结构的头，magic字段是字节顺序。version_major version_minor分别是主版本号和次版本号。 thiszone代表时区， snaplen是数据包的最大长度，一般设置为65535. linktype表示链路类型。可以看到pcap_file_header存储的是，录制这个包的时候的网络状态。 pcap_pkthdr 储存的是数据包的结构。包括数据包的时间戳和包长。在这个结构之后，紧跟着就是一段长为len的数据字段，表示的是这个pkthdr所指的数据包，是二层数据包结构。这个len同时也指向了下一个数据包的位置，即偏移到len+1的位置。 在写入的时候，就是按照上图所示，一个pcap_file_hdr,然后pcap_pkthdr1,pkt_data1,pcap_pkthdr2,pkt_data2,这么写入的。1pcap_file_hdr-&gt;pcap_pkthdr-&gt;pkt_data-&gt;pcap_pkthdr-&gt;pkt_data-&gt;pcap_pkthdr-&gt;pkt_data-&gt;pcap_pkthdr-&gt;pkt_data-&gt;... 所以在读取pcap文件的时候，实际上是线性的访问数据包的。只有读取了第n个数据包，你才能访问的到底n+1个数据包。 注意的坑pcap_pkthdr中的timeval是32位。它的实际结构应该是这样的：1234struct _timeval &#123; uint32_t tv_sec; /* seconds */ uint32_t tv_usec; /* microseconds */&#125;; 在64位系统中，timeval中两个字段都是uint64_t的值。所以如果没有注意到这一点，会出现字段错误。导致保存的pcap包无法被wireshark等工具正常识别。 性能优化在性能上，主要的瓶颈在于写入硬盘。如果程序在每次拿到一个包就写入到硬盘中，就会造成频繁的小文件的写入。这样发挥不了硬盘的最大速度。可以使用一个内存buf来把数据先缓存在内存中，等到了一定大小（比如16M）或者pcap文件写入完毕后再写入硬盘。 架构上的优化程序上的优化最高能够让写包速度达到100Mbps。而相对的，硬盘的最高速度应该是在1000Mbps以上，网卡的性能则可以达到10000Mbps上。所以实际上写包速率是满足不了高性能捕包的写包需求的。这个时候就需要从架构上优化了。 有两种思路可以从架构上优化，第一种是使用多线程并行。每个线程都进行捕包-&gt;解析包-&gt;写入包-&gt;再捕包的过程。这个过程能够提升一定的性能。但是会有几个问题： 频繁的中断。 资源争用。 每个线程在写入一个包的时候，在三个过程，需要申请不同的资源，分别是网卡资源，CPU计算资源和硬盘IO资源。系统的中断和切换资源需要消耗一定的时间。此外，资源争用的问题也会发生，这主要体现在硬盘的资源上。在录制包的场景下，硬盘资源是瓶颈资源。这个时候多个线程在频繁请求硬盘资源，会导致硬盘的写入性能下降。比如我有100的时间片，这100的时间片中，可能只有80的时间片用在了真正的写入硬盘中，其他的时间片都花费在了资源调度上。这会使每个线程的性能不及原来单线程的时候，而且硬盘也无法发挥自己百分百的性能。 另一种是使用多线程并发。每个线程都只干一件事情。捕包有捕包的线程，解析包有解析包的线程，写入包有写入包的线程。这样在线程间的资源竞争就能够被避免。在实际的项目中，甚至把写入包之后的内存释放都单独分出一个线程。就是为了让硬盘IO的效率达到最大。实际的效果，能够使程序支持1000Mbps的录包速度。如果需要再提高性能，就可能需要使用SSD，或者分布式存储，磁盘阵列等来解决了。","tags":[{"name":"DPDK","slug":"DPDK","permalink":"https://nachtz.github.io/tags/DPDK/"},{"name":"Linux","slug":"Linux","permalink":"https://nachtz.github.io/tags/Linux/"},{"name":"网络","slug":"网络","permalink":"https://nachtz.github.io/tags/网络/"}]},{"title":"LeetCode Weekly Contest 9 第九周周赛","date":"2016-10-16T06:11:31.000Z","path":"2016/10/16/leetcode_weekly_contest9/","text":"422. Valid Word SquareGiven a sequence of words, check whether it forms a valid word square. A sequence of words forms a valid word square if the kth row and column read the exact same string, where 0 ≤ k &lt; max(numRows, numColumns).Note: 1. The number of words given is at least 1 and does not exceed 500. 2. Word length will be at least 1 and does not exceed 500. 3. Each word contains only lowercase English alphabet a-z. 大致就是讲给定一组string数组，判断string数组是不是符合要求。要求方块横着读和竖着读是一样的。直接判断就行了。golang AC代码：123456789101112131415161718func validWordSquare(words []string) bool &#123; str := \"\" for i:=0 ;i&lt; len(words);i++&#123; str = \"\" for j:=0;j&lt;len(words);j++&#123; if i &lt; len(words[j])&#123; str += string(words[j][i]) &#125;else&#123; break &#125; &#125; if str != words[i]&#123; return false &#125; &#125; return true&#125; 423. Reconstruct Original Digits from EnglishGiven a non-empty string containing an out-of-order English representation of digits 0-9, output the digits in ascending order. Note: Input contains only lowercase English letters. Input is guaranteed to be valid and can be transformed to its original digits. That means invalid inputs such as “abc” or “zerone” are not permitted. Input length is less than 50,000. 给一串乱序的字母序列，求这个字母序列重组之后所代表的数字串。比如：123Input: \"owoztneoer\"Output: \"012\" 题目中说给出的字母序列都是必定合法而且唯一的。 这题主要是根据0-9的英文中独占的字母来进行判断的。判断的顺序如下： 数字 英文 字母 0 zero z 6 six s 2 two w 7 seven s 4 four u 5 five v 1 one o 9 nine n 8 eight i 3 three t 从表的第一项开始，我们首先可以通过z的个数确定0的个数，然后通过s确定6的个数。依次类推。需要注意的是9的个数是n的个数的一半。最后就能得到乱序序列的原来的数字组合了。golang AC代码：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980func originalDigits(s string) string &#123; nums := []string&#123;\"zero\",\"one\",\"two\",\"three\",\"four\",\"five\",\"six\",\"seven\",\"eight\",\"nine\"&#125; var count [10]int var acount [26]int for i:=0;i&lt;len(s);i++&#123; acount[int(s[i]-'a')] ++ &#125; if acount[25]&gt;0&#123; str := nums[0] count[0] = acount[25] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[0] &#125; &#125; if (acount[int('x'-'a')]&gt;0)&#123; str := nums[6] count[6] = acount[int('x'-'a')] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[6] &#125; &#125; if (acount[int('w'-'a')]&gt;0)&#123; str := nums[2] count[2] = acount[int('w'-'a')] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[2] &#125; &#125; if (acount[int('s'-'a')]&gt;0)&#123; str := nums[7] count[7] = acount[int('s'-'a')] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[7] &#125; &#125; if (acount[int('u'-'a')]&gt;0)&#123; str := nums[4] count[4] = acount[int('u'-'a')] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[4] &#125; &#125; if (acount[int('v'-'a')]&gt;0)&#123; str := nums[5] count[5] = acount[int('v'-'a')] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[5] &#125; &#125; if (acount[int('o'-'a')]&gt;0)&#123; str := nums[1] count[1] = acount[int('o'-'a')] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[1] &#125; &#125; if (acount[int('n'-'a')]&gt;0)&#123; str := nums[9] count[9] = acount[int('n'-'a')]/2 for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[9] &#125; &#125; if (acount[int('i'-'a')]&gt;0)&#123; str := nums[8] count[8] = acount[int('i'-'a')] for i:=0;i&lt;len(str);i++&#123; acount[int(str[i]-'a')] -= count[8] &#125; &#125; count[3] = acount[int('r'-'a')] str := \"\" for i:=0;i&lt;=9;i++&#123; for j:=0;j&lt;count[i];j++&#123; str += string(i+'0') &#125; &#125; return str&#125; 424. Longest Repeating Character ReplacementGiven a string that consists of only uppercase English letters, you can replace any letter in the string with another letter at most k times. Find the length of a longest substring containing all repeating letters you can get after performing the above operations.给定一串仅由大写字母组成的字符串，和一个数字k。假定这个字符串最多有k个字母能被替换成其他字母。求这个替换的过程中，最长的连续重复序列的长度。这道题可以用枚举法，先假设以求最长的连续的A,那么在整个序列中，把不是A的点都标出来。然后看看把这些点中的某K个换成A。求出这个换的过程中的最长长度。算法复杂度是o(n).AC golang代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func characterReplacement(s string, k int) int &#123; dp := make([]int,len(s)+1) var ch [26]bool max := 0 if k == 0&#123; length := 1 for i :=1;i&lt;len(s);i++&#123; if s[i-1] == s[i]&#123; length ++ &#125;else&#123; if max &lt; length&#123; max = length &#125; length = 1 &#125; &#125; if max &lt; length&#123; max = length &#125; return max; &#125; //length := 0 for i :=0;i&lt;len(s);i++&#123; ch[s[i]-'A'] = true &#125; for i :=0;i&lt;26;i++&#123; if ch[i] == false&#123; continue &#125; c := 'A' + i // if c == 75&#123; // fmt.Println(\"break\") // &#125; idx :=0 for j:=0;j&lt;len(s);j++&#123; if int(s[j])!=c&#123; dp[idx] = j idx++ //else&#123; // fmt.Print(j,\" \") &#125; &#125; //fmt.Println(\"|\",c) if idx &lt;= k&#123; return len(s) &#125; if max &lt; dp[k]&#123; max = dp[k] &#125; for j:= k+1;j &lt;idx;j++&#123; if dp[j] - dp[j-k-1] - 1 &gt;= max&#123; max = dp[j] - dp[j-k-1] - 1 //fmt.Println(c) &#125; &#125; &#125; return max&#125; 425 Word Squares没做出来，贴一个别人的python代码，用了trie树加dfs：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970class Solution(object): def wordSquares(self, words): \"\"\" :type words: List[str] :rtype: List[List[str]] \"\"\" self.l = len(words[0]) self.trie = self.build(words) self.res = [] for word in words: self.dfs(words, self.trie, [word]) return self.res def dfs(self, words, trie, lst): if len(lst) == self.l: self.res.append(lst) return prefix = '' for i in range(len(lst)): prefix += lst[i][len(lst)] for s in self.get(trie, prefix): self.dfs(words, trie, lst + [s]) def build(self, words): trie = &#123;&#125; for word in words: t = trie for c in word: if c not in t: t[c] = &#123;&#125; t = t[c] t['#'] = '#' return trie def get(self, trie, prefix): res = [] t = trie for c in prefix: if c not in t: return res t = t[c] for s in self.getall(t): res.append(prefix + s) return res def getall(self, t): res = [] if '#' in t: return [''] for c in t: if c != '#': for s in self.getall(t[c]): res.append(c + s) return res","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"在Docker中运行DPDK","date":"2016-10-16T04:37:31.000Z","path":"2016/10/16/dpdk_docker/","text":"版本Docker：1.12.1DPDK:16.07 Docker的安装在Ubuntu中docker的安装还是很简单的。参考官方文档^1就行了。需要注意的是只能在64位，linux版本号不低于3.11.0-15-generic的发行版上运行。所以在OpenVZ的VPS上不能运行。 制造DPDK的Docker镜像这边主要参考的是网上的一篇博客^1和红帽的Github[^2]来写Dockerfile的。Dockerfile如下：12345678910111213141516171819FROM ubuntuMAINTAINER NachtZ&lt;nachtz@outlook.com&gt;LABEL RUN docker run -it --privileged -v /sys/bus/pci/devices:/sys/bus/pci/devices -v /sys/kernel/mm/hugepages:/sys/kernel/mm/hugepages -v /sys/devices/system/node:/sys/devices/system/node -v /dev:/dev --name NAME -e NAME=NAME -e IMAGE=IMAGE IMAGE&quot;# Setup yum repos, or use subscription-manager# Install DPDK support packages.RUN apt-get update &amp;&amp; apt-get install -y libpcap-dev wget xz-utils gcc automake autoconf libtool make # Build DPDK and pktgen-dpdk for x86_64-native-linuxapp-gcc.WORKDIR /rootCOPY ./build_dpdk.sh /root/build_dpdk.shCOPY ./dpdk-profile.sh /etc/profile.d/#RUN /root/build_dpdk.sh# Defaults to a bash shell, you could put your DPDK-based application here.CMD [&quot;/bin/bash&quot;] 这个Dockerfile的注解如下：FROM ubuntu：说明该镜像的源镜像是Ubuntu。MAINTAINER NachtZ&lt;nachtz@outlook.com&gt;:介绍镜像的作者。 LABEL RUN docker run -it --privileged -v /sys/bus/pci/devices:/sys/bus/pci/devices -v /sys/kernel/mm/hugepages:/sys/kernel/mm/hugepages -v /sys/devices/system/node:/sys/devices/system/node -v /dev:/dev --name NAME -e NAME=NAME -e· IMAGE=IMAGE IMAGE&quot;: 镜像的标签。 RUN apt-get update &amp;&amp; apt-get install -y libpcap-dev wget xz-utils gcc automake autoconf libtool make：安装DPDK所需要的依赖程序，因为在Docker中的系统都是比较精简的，所以很多程序都需要自己安装。 123WORKDIR /rootCOPY ./build_dpdk.sh /root/build_dpdk.shCOPY ./dpdk-profile.sh /etc/profile.d/ 上面这段话是把Dockerfile同目录下./build_dpdk.sh,./dpdk-profile.sh拷贝到镜像里面去。 CMD [&quot;/bin/bash&quot;]:指定动作是打开一个bash。 到此为止，一个可以用来安装DPDK的镜像就完成了。接下来就是打开它。 在Docker中安装DPDK在shell中运行：docker run -it --privileged -v /sys/bus/pci/devices:/sys/bus/pci/devices -v /sys/kernel/mm/hugepages:/sys/kernel/mm/hugepages -v /sys/devices/system/node:/sys/devices/system/node -v /dev:/dev xxx（最后的xxx表示的是之前的镜像的名字）在运行这个之前，需要将宿主机的DPDK环境都配置好。比如hugepage，以及转载好DPDK驱动的端口。之后运行docker run， --privileged -v /sys/bus/pci/devices:/sys/bus/pci/devices -v /sys/kernel/mm/hugepages:/sys/kernel/mm/hugepages -v /sys/devices/system/node:/sys/devices/system/node 这段话的意思就是给Docker容器权限来使用宿主机的端口，hugepage等。 之后我们进入到Docker的容器中。在容器的root目录下可以看到之前拷贝的./build_dpdk.sh。内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/bin/bash################################################################################## build_dpdk.sh## - Build DPDK and pktgen-dpdk for ## Usage: Adjust variables below before running, if necessary.## MAINTAINER: jeder@redhat.com################################################################################################################################################################### Define Global Variables and Functions################################################################################URL=http://fast.dpdk.org/rel/dpdk-16.04.tar.xzBASEDIR=/rootVERSION=16.04PACKAGE=dpdkDPDKROOT=$BASEDIR/$PACKAGE-$VERSIONCONFIG=x86_64-native-linuxapp-gcc# Download/Build DPDKcd $BASEDIRwget $URLtar -xf $PACKAGE-$VERSION.tar.xzcd $DPDKROOT sed -i 's/CONFIG_RTE_EAL_IGB_UIO=y/CONFIG_RTE_EAL_IGB_UIO=n/' $&#123;DPDKROOT&#125;/config/common_linuxapp \\ &amp;&amp; sed -i 's/CONFIG_RTE_LIBRTE_KNI=y/CONFIG_RTE_LIBRTE_KNI=n/' $&#123;DPDKROOT&#125;/config/common_linuxapp \\ &amp;&amp; sed -i 's/CONFIG_RTE_KNI_KMOD=y/CONFIG_RTE_KNI_KMOD=n/' $&#123;DPDKROOT&#125;/config/common_linuxapp # don't build unnecessary stuff, can be reversed in dpdk_config.shsed -i 's/CONFIG_RTE_APP_TEST=y/CONFIG_RTE_APP_TEST=n/' $&#123;DPDKROOT&#125;/config/common_base \\ &amp;&amp; sed -i 's/CONFIG_RTE_TEST_PMD=y/CONFIG_RTE_TEST_PMD=n/' $&#123;DPDKROOT&#125;/config/common_base \\ &amp;&amp; sed -i 's/CONFIG_RTE_EAL_IGB_UIO=y/CONFIG_RTE_EAL_IGB_UIO=n/' $&#123;DPDKROOT&#125;/config/common_base \\ &amp;&amp; sed -i 's/CONFIG_RTE_LIBRTE_IGB_PMD=y/CONFIG_RTE_LIBRTE_IGB_PMD=n/' $&#123;DPDKROOT&#125;/config/common_base \\ &amp;&amp; sed -i 's/CONFIG_RTE_LIBRTE_IXGBE_PMD=y/CONFIG_RTE_LIBRTE_IXGBE_PMD=n/' $&#123;DPDKROOT&#125;/config/common_base \\make config T=$CONFIGsed -ri 's,(PMD_PCAP=).*,\\1y,' build/.configmake config T=$CONFIG install 这个文档来自^3。我依照DPDK 16.04中的文档和博客[^2]来改造的。在博客[^2]中提到： One thing that is important is to not rely on kernel headers; doing so would be seriously non portable. The uio and igb_uio kernel modules have to be built and installed by the host that will run the DPDK container. Therefore, we configure the SDK to not compile kernel modules, and therefore not require installing kernel headers on the build system. 就是说在Docker中，用到的网卡驱动是宿主机的驱动，所以不需要编译网卡内核驱动。在./build_dpdk.sh中，的两行sed语句就是在修改编译配置。 手动运行完./build_dpdk.sh之后，就可以正常编译运行DPDK的程序了。比如可以：12345$:export RTE_SDK=/root/dpdk-16.04$:export RTE_TARGET=x86_64-native-linuxapp-gcc$:cd dpdk-16.04/example/helloworld$:make$:./build/helloworld 就可以看到helloworld正常的运行了。 Github这是修改完成之后的Docker的Dockerfile和两个sh文件。NachtZ/docker-dpdk 参考资料 Jason的博客[^2] Redhat的dpdk_docker^3 Reference[^2]:Jason 的博客","tags":[{"name":"DPDK","slug":"DPDK","permalink":"https://nachtz.github.io/tags/DPDK/"},{"name":"Docker","slug":"Docker","permalink":"https://nachtz.github.io/tags/Docker/"}]},{"title":"LeetCode Weekly Contest 8 第八周周赛","date":"2016-10-09T06:37:31.000Z","path":"2016/10/09/leetcode_weekly_contest8/","text":"不知为何生成该博客会出现内存溢出问题。贴个其他地方的链接。LeetCode Weekly Contest 8 第八周周赛","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"LeetCode Weekly Contest 6 第六周周赛","date":"2016-09-25T06:08:49.000Z","path":"2016/09/25/leetcode_weekly_contest6/","text":"404. Sum of Left Leaves不解释123456789101112131415161718func isLeaf(root * TreeNode) bool&#123; if root == nil || root.Left!=nil || root.Right!=nil&#123; return false &#125; return true;&#125;func sumOfLeftLeaves(root *TreeNode) int &#123; res := 0 if root != nil&#123; if isLeaf(root.Left)&#123; res += root.Left.Val &#125;else&#123; res += sumOfLeftLeaves(root.Left) &#125; res += sumOfLeftLeaves(root.Right) &#125; return res&#125; 405. Convert a Number to Hexadecimal常规的10进制转16进制。负数的转换需要先转为补码再计算。注意用long long int 防止溢出。12345678910111213141516171819202122class Solution &#123;public: string toHex(int num) &#123; string a[] = &#123; \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\" &#125;; string res; if (num == 0)&#123; return \"0\"; &#125; long long int t; if (num &lt;0)&#123; t = unsigned(num); &#125; else&#123; t = num; &#125; while (t&gt;0)&#123; res = a[t % 16] + res; t /= 16; &#125; return res; &#125;&#125;; 406. Queue Reconstruction by Heighto(n*n)的复杂度。1.将人排序，以前置比他高的人数大小排列，相等的时候按照高度从低到高。2.取排列完第一位，将其取出队列。然后更新下排列中的人情况。即将比他矮的人中，front的人数-1。3.重复操作1，2直到队列中的人都被取出。4.还原队列中的front的情况。因为在第二步中，front的情况会被改写，所以需要恢复。12345678910111213141516171819202122232425262728293031323334353637383940414243type P [][]int func(p P) Len()int&#123; return len(p)&#125;func(p P)Swap(i,j int)&#123; p[i][0],p[i][1],p[j][0],p[j][1] = p[j][0],p[j][1],p[i][0],p[i][1]&#125;func (p P)Less(i,j int)bool&#123; if p[i][1]!=p[j][1]&#123; return p[i][1] &lt; p[j][1] &#125; return p[i][0] &lt; p[j][0]&#125;//1.sort//2.取当前队列func reconstructQueue(people [][]int) [][]int &#123; res := make([][]int,len(people)) for i:=0;i&lt;len(res);i++&#123; res[i] = make([]int,2) &#125; n := len(people) for i:=0;i&lt;n;i++&#123; sort.Sort(P(people)) res[i][0],res[i][1] = people[0][0],people[0][1] for j:=1;j&lt;len(people);j++&#123; if people[0][0] &gt;=people[j][0]&#123; people[j][1] --; &#125; &#125; people = people[1:] &#125; for i :=1;i&lt;len(res);i++ &#123; count :=0 for j :=0;j&lt;i;j++ &#123; if res[i][0] &lt;= res[j][0]&#123; count ++; &#125; &#125; res[i][1] = count &#125; return res;&#125; 407. Trapping Rain Water II下面的做法超时了。正解网上找了一个。11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495func dfs(heightMap [][]int, x,y int)&#123; if x &lt; 0 || x &gt;= len(heightMap) || y &lt;0 || y &gt;= len(heightMap[0])&#123; return &#125; if heightMap[x][y] != 0&#123; return &#125; heightMap[x][y] = 65535 dfs(heightMap,x+1,y) dfs(heightMap,x-1,y) dfs(heightMap,x,y+1) dfs(heightMap,x,y-1)&#125;func getArea(heightMap [][]int) int&#123; for i:=0;i&lt;len(heightMap[0]);i++&#123; dfs(heightMap,0,i) dfs(heightMap,len(heightMap)-1,i) &#125; for i:=0;i&lt;len(heightMap);i++&#123; dfs(heightMap,i,0) dfs(heightMap,i,len(heightMap[0])-1) &#125; count :=0 for i :=0;i&lt;len(heightMap);i++&#123; for j:=0;j&lt;len(heightMap[0]);j++&#123; if heightMap[i][j] == 0&#123; count ++ &#125;else if heightMap[i][j] ==65535&#123; heightMap[i][j] = 0; &#125; &#125; &#125; return count&#125;/*func getMin(heightMap [][]int) int&#123; min := 65535 m,n := len(heightMap),len(heightMap[0]) for i:=1;i&lt;m-1;i++&#123; for j:=1;j&lt;n-1;j++&#123; if heightMap[i][j] == 0&#123; continue; &#125; if min &gt; heightMap[i][j]&#123; min = heightMap[i][j] &#125; &#125; &#125; return min&#125;*/func getMin2(heightMap [][]int) int&#123; min := 65535 m,n := len(heightMap),len(heightMap[0]) for i:=0;i&lt;m;i++&#123; for j:=0;j&lt;n;j++&#123; if heightMap[i][j] == 0&#123; continue; &#125; if min &gt; heightMap[i][j]&#123; min = heightMap[i][j] &#125; &#125; &#125; return min&#125;func trapRainWater(heightMap [][]int) int &#123; res ,tmp:= 0,1 if len(heightMap) == 0 || len(heightMap[0]) == 0&#123; return 0 &#125; for true&#123; m,n := len(heightMap),len(heightMap[0]) min := getMin2(heightMap) for i:=0;i&lt;m;i++&#123; for j:=0;j&lt;n;j++&#123; if heightMap[i][j] &lt; min&#123; heightMap[i][j] = 0 continue; &#125; heightMap[i][j] -= min &#125; &#125; min = getMin2(heightMap) if min == 65535&#123; break &#125; tmp = min* getArea(heightMap) res += tmp &#125; return res&#125;","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"LeetCode Weekly Contest 5 第五周周赛","date":"2016-09-18T10:10:18.000Z","path":"2016/09/18/leetcode_weekly_contest5/","text":"第一题: 400. Nth Digit这道题用暴力的直接写出从1到n的所有数字组合而成的字符串会超时。一种解法是：先计算出第n个字符是属于哪个数字的。边计算边统计之前的字符个数total。然后得到这个数字后，将这个数字转为字符串，并取n-total-1这个下标的字符，就是所求。123456789101112131415161718func findNthDigit(n int) int &#123; i := 0 mark, l := 1, 0 total := 0 for i = 1; total &lt; n; i++ &#123; if i &gt;= mark &#123; total += l + 1 l++ mark *= 10 &#125; else &#123; total += l &#125; &#125; i-- total -= l t := strconv.Itoa(i) return int(t[n-total-1] - '0')&#125; 第二题：401. Binary Watch没过，应该是题目有问题。题目中说顺序无所谓但是实际上顺序貌似还是有关系的。用二进制来进行计算。先递归的计算出所有可能的num情况。然后将对应的num读为时间即可。 123456789101112131415161718192021222324252627282930313233343536373839404142var b = []int&#123;1, 2, 4, 8, 16, 32, 64, 128, 256, 512&#125;var ret []stringfunc readTime(num int) &#123; str := \"\" t := num &gt;&gt; 6 if t &gt;= 12 &#123; return &#125; str += strconv.Itoa(t) + \":\" t = num &amp; 63 if t &gt;= 60 &#123; return &#125; if t &lt; 10 &#123; str += \"0\" + strconv.Itoa(t) &#125; else &#123; str += strconv.Itoa(t) &#125; ret = append(ret, str)&#125;func help(now, num, idx int) &#123; if num == 0 &#123; readTime(now) return &#125; if idx &gt;= 10 &#123; return &#125; help(now, num, idx+1) help(now|b[idx], num-1, idx+1)&#125;func readBinaryWatch(num int) []string &#123; ret = []string&#123;&#125; if num == 0 &#123; return []string&#123;\"0:00\"&#125; &#125; for i := 0; i &lt; len(b); i++ &#123; help(b[i], num-1, i+1) &#125; return ret&#125; 第三题：402. Remove K Digits在裁剪的过程中，如果要裁剪掉k个字符，那么在一个字符串中，前k+1一个字符中一定会有至少一个字符被保留下来。所以算法的目的就是递归的找到这个字符，并对这个字符之后的字符串继续进行裁剪，直到得到最后的结果。另外，题目中要求不能有0，所以在得到结果之后还要去掉首部的0。1234567891011121314151617181920212223242526272829303132333435var res stringfunc help(num string, k int) &#123; if k &lt;= 0&#123; res = res + num return &#125; if k &gt;= len(num)&#123; return ; &#125; minIdx := 0 for i:=1;i&lt;=k;i++&#123; if num[i] &lt; num[minIdx]&#123; minIdx = i &#125; &#125; res = res + string(num[minIdx]) new := num[minIdx+1:] help(new,k - minIdx)&#125;func removeKdigits(num string, k int) string &#123; res = \"\" help(num,k) i:=0 for i=0;i&lt;len(res)&amp;&amp;res[i]=='0';i++&#123; &#125; if i&lt;len(res)&#123; res = res[i:] &#125;else&#123; res = \"0\" &#125; return res&#125; 第四题：403. Frog Jump很明显的递归的例子。用一个映射来讲stones[下标]距离 改成 map[距离]下标.然后从0开始起跳。距离为1。每一次进行判断，首先是是不是最后一个石头了，是则返回true。程序over。然后判断判断下目前所在的石头是哪一个。（检索map[stone[idx]+stp]即可知道，为0即不存在，返回false。）接下来就是继续进行跳跃，分别尝试跳跃stp,stp+1,stp-1的距离即可。需要注意stp==0的时候是没有意义的，直接返回false.1234567891011121314151617181920212223var m map[int]intfunc help(stones []int, idx int, stp int) bool &#123; if stp == 0 &#123; return false &#125; if idx == len(stones)-1 &#123; return true &#125; if m[stones[idx]+stp] == 0 &#123; return false &#125; idx = m[stones[idx]+stp] return help(stones, idx, stp-1) || help(stones, idx, stp+1) || help(stones, idx, stp)&#125;func canCross(stones []int) bool &#123; m = make(map[int]int) for i := 0; i &lt; len(stones); i++ &#123; m[stones[i]] = i &#125; return help(stones, 0, 1)&#125;","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"LeetCode Weekly Contest 4 第四周周赛","date":"2016-09-12T04:10:18.000Z","path":"2016/09/12/leetcode_weekly_contest4/","text":"用golang做了1，2，4题，第3题golang总是有问题换成c++来做。代码地址：leetcode solution(golang) ###396. Rotate Function###最暴力的方法莫过于一遍一遍计算。可以得到结果。第二种方法就是利用了前一次的结果。假设数组为[a,b,c,d]那么第一次计算的结果就是：0*a + 1*b + 2*c + 3*d第二次计算的结果是（从右往左旋转）：1*a + 2*b + 3*c + 0*d和之前的结果比：差值为：1*a+1*a+1*a-3*d == 1*a+1*a+1*a+1*d - 3*d所以基于前一次的结果f,可以得到下一次的结果的计算公式：t :=f+sum - A[len(A)-i]*len(A) 12345678910111213141516func maxRotateFunction(A []int) int &#123; sum,f:= 0,0 for i:=0;i&lt;len(A);i++&#123; sum += A[i] f += i*A[i] &#125; m := f for i:=1;i&lt;len(A);i++&#123; t :=f+sum - A[len(A)-i]*len(A) if m &lt; t&#123; m = t &#125; f += sum - A[len(A)-i]*len(A) &#125; return m&#125; ###397. Integer Replacement###很简单的递归计算题目。不过这么做复杂度比较高，能过也说明Leetcode的test case 有点简单了。123456789101112131415func integerReplacement(n int) int &#123; if n &lt;= 1&#123; return 0 &#125; if n %2 == 0&#123; return integerReplacement(n/2)+1 &#125;else&#123; t1,t2 := integerReplacement(n+1),integerReplacement(n-1) if t1 &lt;t2&#123; return t1 +1 &#125;else&#123; return t2 +1 &#125; &#125;&#125; ###398. Random Pick Index###这道题的解法，第一种是创建一个hash表map&lt;int,vector&lt;int&gt;&gt;来保存对应的映射关系。在初始化的时候建表。时间复杂度和空间复杂度都是o(n).在检索的时候直接查表取随机值，时间复杂度为o(1).不过最后会出现MLE错误。原因是leetcode这道题考察的点不是hash表，于是将内存限制为o(1).123456789101112131415161718192021222324//MLE代码class Solution &#123;private: unordered_map&lt;int, vector&lt;int&gt;&gt; m;public: Solution(vector&lt;int&gt; nums) &#123; srand(time(0)); for (int i = 0; i&lt;nums.size(); i++)&#123; if (m.count(nums[i]) == 0)&#123; vector&lt;int&gt; t; t.push_back(i); m[nums[i]] = t; &#125; else&#123; m[nums[i]].push_back(i); &#125; &#125; &#125; int pick(int target) &#123; int r = rand() % m[target].size(); return m[target][r]; &#125;&#125;; 这道题实际上考察的是蓄水池抽样，具体的可以看看这篇Blog。利用蓄水池抽样算法，就可以在不知道整个数组长度的情况下，就能保证各个元素获取的概率是相同的。不过貌似不用蓄水池抽样的方法也能通过。12345678910111213141516171819202122class Solution &#123; vector&lt;int&gt; num;public: Solution(vector&lt;int&gt; nums) &#123; num = nums; &#125; int pick(int target) &#123; int index = -1; int count = 0; for (int i = 0; i &lt; num.size(); i++)&#123; if (num[i] == target)&#123; count++; int r = rand() % count + 1; if (r == count)&#123; index = i; &#125; &#125; &#125; return index; &#125;&#125;; 顺带吐槽下leetcode的Golang. 这道题让我意识到Golang不适合在leetcode下刷题用。碰到大数据的题目几乎都会挂，比如109题和239题。还得发邮件给support才能在后台改成通过。这道题的golang解法提示WA。但是错误的test case在本地运行是可以通过的。12345678910111213141516171819202122232425type Solution struct &#123; nums []int&#125;func Constructor(nums []int) Solution &#123; var s Solution s.nums = nums return s&#125;func (this *Solution) Pick(target int) int &#123; idx,count := -1,0 for i:=0;i&lt;len(this.nums);i++&#123; if this.nums[i] == target&#123; count ++ r := rand.Intn(count) + 1 if r== count&#123; idx = i &#125; &#125; &#125; return idx&#125; ###399. Evaluate Division###这种解法最后也能过也是DIAO.o(n*n)的复杂度。遍历两遍。第一遍遍历提供的数据，利用提供的数据计算出所有的两两可提供的结果。比如提供给你 a/b b/c能得到a/b b/a a/a /b/b a/c c/a这几个结果。用map记录这些元素。第二遍遍历第一遍所得到的map进行同样的操作，来二次推导得到的结果。之后的检索操作就是查表操作。没想到这样的方法也能过。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283func calcEquation(equations [][]string, values []float64, query [][]string) []float64 &#123; m := make(map[[2]string]float64) //tm := make(map[string]float64) for i:=0;i&lt;len(equations);i++&#123; a,b :=equations[i][0],equations[i][1] m[[2]string&#123;a,b&#125;] =values[i] m[[2]string&#123;b,a&#125;] = 1/values[i] m[[2]string&#123;a,a&#125;] =1.0 m[[2]string&#123;b,b&#125;] =1.0 for j :=i+1;j&lt;len(equations);j++&#123; //in here to construct the map c,d := equations[j][0],equations[j][1] if a!=c &amp;&amp;a!=d &amp;&amp; b!=c &amp;&amp; b!=d&#123; continue// can't get any new info &#125; if a == c &amp;&amp;b == d || a == d&amp;&amp; b == c&#123; continue// can't get any new info &#125; if a == c&#123; m[[2]string&#123;d,b&#125;] = values[i]/values[j] m[[2]string&#123;b,d&#125;] = values[j]/values[i] &#125; if a == d&#123; m[[2]string&#123;c,b&#125;] = values[i]*values[j] m[[2]string&#123;b,c&#125;] = 1/(values[i]*values[j]) &#125; if b == c&#123; m[[2]string&#123;a,d&#125;] = values[i]*values[j] m[[2]string&#123;d,a&#125;] = 1/(values[j]*values[i]) &#125; if b == d&#123; m[[2]string&#123;a,c&#125;] = values[i]/values[j] m[[2]string&#123;c,a&#125;] = values[j]/values[i] &#125; &#125; &#125; for k,v := range m&#123; a,b := k[0],k[1] m[[2]string&#123;a,b&#125;] =v m[[2]string&#123;b,a&#125;] = 1/v m[[2]string&#123;a,a&#125;] =1.0 m[[2]string&#123;b,b&#125;] =1.0 for k1,v1 := range m&#123; //in here to construct the map c,d := k1[0],k1[1] if a!=c &amp;&amp;a!=d &amp;&amp; b!=c &amp;&amp; b!=d&#123; continue// can't get any new info &#125; if a == c &amp;&amp;b == d || a == d&amp;&amp; b == c&#123; continue// can't get any new info &#125; if a == c&#123; m[[2]string&#123;d,b&#125;] = v/v1 m[[2]string&#123;b,d&#125;] = v1/v &#125; if a == d&#123; m[[2]string&#123;c,b&#125;] = v*v1 m[[2]string&#123;b,c&#125;] = 1/(v*v1) &#125; if b == c&#123; m[[2]string&#123;a,d&#125;] = v*v1 m[[2]string&#123;d,a&#125;] = 1/(v*v1) &#125; if b == d&#123; m[[2]string&#123;a,c&#125;] = v/v1 m[[2]string&#123;c,a&#125;] = v1/v &#125; &#125; &#125; tmp := [2]string&#123;\"\",\"\"&#125; var ret []float64 for i:=0;i&lt;len(query);i++&#123; tmp[0],tmp[1] = query[i][0],query[i][1] v, ok := m[tmp] if ok&#123; ret = append(ret,v) &#125;else&#123; ret = append(ret,-1.0) &#125; &#125; return ret&#125;","tags":[{"name":"Leetcode","slug":"Leetcode","permalink":"https://nachtz.github.io/tags/Leetcode/"},{"name":"Golang","slug":"Golang","permalink":"https://nachtz.github.io/tags/Golang/"}]},{"title":"将DPDK移植到snort上的DAQ","date":"2016-08-06T10:16:34.000Z","path":"2016/08/06/dpdk_daq/","text":"DAQ 与Snort在snort-daq中，daq的控制流程是这样的。如上所述，Snort在初始化的时候载入了daq。这个时候snort的所调用的api是daq_load_modules。也就是说，这个时候在主线程没有启动网卡，初始化实例的操作。在初始化整个snort之后（载入配置，载入daq及其他各个模块等等）。snort就进入了分析的阶段了。这个阶段的主角是pig，或者说更本质的，是pig下的analyzer。Snort下面开n个pig线程。pig线程下面调用analyzer来进行包解析。包解析的过程中是在pig线程中多线程并行进行的。每一个analyzer下面都初始化一个daq instance并调用acquire进行抓包并分析。每一个daq instance下面都有一个或多个网卡来获取数据。因为目的主要是介绍daq，所以怎么解析就不提了。从上图和上面的介绍就可以看得出来，一个snort下面有多个daq instance并行运行。每一个daq instance都会进行初始化操作，占用系统资源，获取网卡，抓包，调用callback，之间相互独立。并且是单线程的。 DAQ与DPDK如上面所介绍的。DAQ在设计的时候是单线程的。在本身的实现的几个模块中（Netmap,pcap等等）完全没有涉及到多线程的事情。在snort中的调用也是单线程并行调用的，相互之间各不影响。而Inter的DPDK在多线程方面则有限制。它所初始化的EAL层只能初始化一次。一个程序中只能运行一个dpdk主程序。所以就没有办法在snort中使用多线程。因为如果在snort中使用了多线程。那么实际上每个线程都会去尝试初始化dpdk的EAL。那么就会出错，导致最后只有一个线程能够成功初始化并启动。所以如果要想实现一个支持snort多线程的daq。就需要修改daq中api的逻辑。在实现中，利用线程id来绑定网卡。在daq的content中加入了一个nic-threadid的映射表。然后每个网卡都有一个独立的instance存储原本在daq_content中的信息。然后在线程调用daq相关函数的时候，都会先利用threadid来进行检索这个instance进行操作。通过这个方法就能够将dpdk中的各个网卡独立运行。 Github地址daq_dpdk基于的是dpdk16.04, daq2.1.0,snort 3.0 a04.使用方法在项目主页中。","tags":[{"name":"DPDK","slug":"DPDK","permalink":"https://nachtz.github.io/tags/DPDK/"},{"name":"Snort","slug":"Snort","permalink":"https://nachtz.github.io/tags/Snort/"}]},{"title":"dpdk_ring剥离（单线程版）","date":"2016-06-17T10:19:59.000Z","path":"2016/06/17/dpdk_ring/","text":"DPDK_RING 剥离(sc)dpdk中的ring结构的原理在官方的doc中有。详细的介绍了单线程和多线程下的ring的结构的实现。其中线程安全的ring的出入队中没有用到锁，这个结构是比较巧妙的。此外，和一般的ring设计相比，dpdk的ring中减少了比较的次数和减法的次数。考虑了很多性能方面的东西。目前就剥离了单线程版的。代码如下： daq_ring.h12345678910111213141516171819202122232425262728293031323334353637383940414243#ifndef DAQ_RING_H#define DAQ_RING_H#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;//#include &lt;pthread.h&gt;typedef struct _daq_ring&#123; // pthread_mutex_t mutex; int size; int mask; int cons_head; int cons_tail; int prod_head; int prod_tail; void * ring[0];&#125;;typedef struct _daq_ring daq_ring;//create a ring which can contain size's objects.daq_ring * daq_ring_create(int num);//fre a ring.int daq_ring_free(daq_ring * r);//see whether a ring is empty.int daq_ring_isEmpty(daq_ring * r);//see whether a ring is full.int daq_ring_isFull(daq_ring * r);//see the number of objects in ring now.int daq_ring_count(daq_ring * r);//see the size of a ring.int daq_ring_getSize(daq_ring *r);//see the number of objects can be inputed into the ring now.int daq_ring_freeCount(daq_ring * r);//enqueue objects into a ring.int daq_ring_enqueue(daq_ring * r, void * const *obj_table, int num,int mc);//dequeue objects from a ring.int daq_ring_dequeue(daq_ring * r, void **obj_table, int num,int mc);#endif//end of daq_ring.h -daq_ring.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203#include \"daq_ring.h\"/*typedef struct _daq_ring&#123; pthread_mutex_t mutex; unsigned int size; void * head; void * tail; void * memhead;&#125;daq_ring;*/daq_ring * daq_ring_create(int num)&#123; daq_ring * r = NULL; if(num &lt;=0)return NULL; r = (daq_ring *)malloc(sizeof(daq_ring) + num*sizeof(void*)); if(r == NULL)&#123; return NULL; &#125; r-&gt;size = num; r-&gt;mask = num-1; r-&gt;prod_head = r-&gt;prod_tail = r-&gt;cons_head = r-&gt;cons_tail = 0; // pthread_mutex_init(&amp;r-&gt;mutex,NULL); return r;&#125;//fre a ring.int daq_ring_free(daq_ring * r)&#123; free(r);&#125;//see whether a ring is empty.int daq_ring_isEmpty(daq_ring * r)&#123; return r-&gt;cons_tail == r-&gt;prod_tail;&#125;//see whether a ring is full.int daq_ring_isFull(daq_ring * r)&#123; return (((r-&gt;cons_tail - r-&gt;prod_tail -1)&amp;r-&gt;mask)==0);&#125;//see the number of objects in ring now.int daq_ring_count(daq_ring * r)&#123; return ((r-&gt;prod_tail - r-&gt;cons_tail)&amp;r-&gt;mask);&#125;//see the size of a ring.int daq_ring_getSize(daq_ring *r)&#123; return r-&gt;size;&#125;//see the number of objects can be inputed into the ring now.int daq_ring_freeCount(daq_ring * r)&#123; return ((r-&gt;cons_tail - r-&gt;prod_tail - 1) &amp; r-&gt;mask);&#125;//enqueue objects into a ring.int daq_ring_enqueue(daq_ring * r, void * const *obj_table, int num,int mc)&#123; int prod_head = r-&gt;prod_head; int cons_tail = r-&gt;cons_tail; int prod_next = prod_head +1; int mask = r-&gt;mask; int i ; int free = mask + cons_tail -prod_head; if(num &gt;free)&#123; if(free == 0)return 0; num = free; &#125; prod_next = prod_head +num; r-&gt;prod_head = prod_next; &#123; const int size = r-&gt;size; int idx = prod_head &amp; mask; if(idx + num &lt; size)&#123; for (i = 0; i &lt; (num &amp; ((~(unsigned)0x3))); i+=4, idx+=4) &#123; r-&gt;ring[idx] = obj_table[i]; r-&gt;ring[idx+1] = obj_table[i+1]; r-&gt;ring[idx+2] = obj_table[i+2]; r-&gt;ring[idx+3] = obj_table[i+3]; &#125; switch (num &amp; 0x3) &#123; case 3: r-&gt;ring[idx++] = obj_table[i++]; case 2: r-&gt;ring[idx++] = obj_table[i++]; case 1: r-&gt;ring[idx++] = obj_table[i++]; &#125; &#125;else&#123; for (i =0;idx&lt;size;++i,++idx) r-&gt;ring[idx] = obj_table[i]; for(idx = 0;i&lt;num;++i,++idx) r-&gt;ring[idx] = obj_table[i]; &#125; &#125; r-&gt;prod_tail = prod_next; return num;&#125;//dequeue objects from a ring.int daq_ring_dequeue(daq_ring * r, void **obj_table, int num,int mc)&#123; int cons_head,prod_tail; int cons_next,entries; int i; int mask = r-&gt;mask; cons_head = r-&gt;cons_head; prod_tail = r-&gt;prod_tail; entries = prod_tail - cons_head; if(num &gt; entries)&#123; if(entries == 0)return 0; num = entries; &#125; cons_next = cons_head + num; r -&gt; cons_head = cons_next; &#123; int idx = cons_head &amp; mask; int size = r-&gt; size; if (idx + num &lt; size) &#123; for (i = 0; i &lt; (num &amp; (~(unsigned)0x3)); i+=4, idx+=4) &#123; obj_table[i] = r-&gt;ring[idx]; obj_table[i+1] = r-&gt;ring[idx+1]; obj_table[i+2] = r-&gt;ring[idx+2]; obj_table[i+3] = r-&gt;ring[idx+3]; &#125; switch (num &amp; 0x3) &#123; case 3: obj_table[i++] = r-&gt;ring[idx++]; case 2: obj_table[i++] = r-&gt;ring[idx++]; case 1: obj_table[i++] = r-&gt;ring[idx++]; &#125; &#125; else &#123; for (i = 0; idx &lt; size; i++, idx++) obj_table[i] = r-&gt;ring[idx]; for (idx = 0; i &lt; num; i++, idx++) obj_table[i] = r-&gt;ring[idx]; &#125; &#125; r-&gt;cons_tail = cons_next; return num;&#125;void daq_ring_stat(daq_ring * r)&#123; printf(\"***********************************************\\n\"); printf(\"Daq_ring's size is %d\\n\",daq_ring_getSize(r)); printf(\"Daq_ring's objects now is %d.\\n\",daq_ring_count(r)); printf(\"Daq_ring's free space is %d\\n\",daq_ring_freeCount(r)); printf(\"Daq_ring is %s now.\\n\",daq_ring_isEmpty(r)?\"empty\":\"not empty\"); printf(\"Daq_ring is %s now.\\n\",daq_ring_isFull(r)?\"full\":\"not full\"); printf(\"***********************************************\\n\");&#125;void print_ptr(daq_ring *r)&#123; printf(\"r-&gt;cons:%p %p\\n\", r-&gt;cons_head, r-&gt;cons_tail); printf(\"r-&gt;prod:%p %p\\n\",r-&gt;prod_head,r-&gt;prod_tail); printf(\"r-&gt;ring[0]:%p\\n\",&amp;r-&gt;ring[0]); &#125;int test1()&#123; char * str[] = &#123; \"t1\",\"t2\",\"t3\",\"t4\",\"t5\",\"t6\",\"t7\",\"t8\",\"t9\",\"t10\",\"t11\",\"t12\",\"t13\" &#125;; void * ctx[12]; int i; for(i =0;i&lt;10;++i) printf(\"%s\\n\",str[i]); daq_ring * r = daq_ring_create(9); daq_ring_stat(r); print_ptr(r); daq_ring_enqueue(r,str,8,1); daq_ring_stat(r); print_ptr(r); daq_ring_dequeue(r,ctx,8,1); for(int i =0;i&lt;8;++i) printf(\"%s\\n\",(char *)ctx[i]); daq_ring_stat(r);print_ptr(r); daq_ring_enqueue(r,str,8,1); daq_ring_stat(r); print_ptr(r); daq_ring_dequeue(r,ctx,8,1); for(i =0;i&lt;10;++i) printf(\"%s\\n\",(char *)ctx[i]); return 0;&#125;int test2()&#123; int i; char * str[] = &#123; \"t1\", \"t2\", \"t3\", \"t4\", \"t5\", \"t6\", \"t7\", \"t8\", \"t9\", \"t10\", \"t11\", \"t12\", \"t13\", \"t14\", \"t15\", \"t16\", \"t17\" &#125;; void * ctx[18]; daq_ring * r = daq_ring_create(16); daq_ring_enqueue(r,str,14,1); daq_ring_stat(r); print_ptr(r); daq_ring_dequeue(r,ctx,4,1); for(i =0;i&lt;4;++i) printf(\"%s\\n\",(char *)ctx[i]); daq_ring_stat(r); print_ptr(r); daq_ring_enqueue(r,&amp;str[5],5,1); daq_ring_stat(r); print_ptr(r); daq_ring_dequeue(r,ctx,15,1); for(i =0;i&lt;15;++i) printf(\"%s\\n\",(char *)ctx[i]); daq_ring_stat(r); print_ptr(r);&#125;int main()&#123; test2(); return 0;&#125;","tags":[{"name":"DPDK","slug":"DPDK","permalink":"https://nachtz.github.io/tags/DPDK/"}]},{"title":"DPDK杂记","date":"2016-06-17T10:19:02.000Z","path":"2016/06/17/dpdk_note/","text":"DPDK编译动态库将common_linuxapp中的CONFIG_RTE_BUILD_SHARED_LIB和CONFIG_RTE_BUILD_COMBINE_LIBS都改为y，重新编译。将生成的lib文件拷贝到linux的lib中。（在dpdk16.04中，combine这个选项被取消了。邮件组中提到说是默认就是combine了。但是实际编译中发现不同的网卡驱动还是没有编译在一起。拷贝的时候都需要拷贝过去。）之后就是修改Makefile.将makefile中的1include $(RTE_SDK)/mk/rteextapp.mk 改为1include $(RTE_SDK)/mk/rte.extshared.mk 把binary name中的app改为1SHARED = yourname.so 最后再加上库：1LDLIBS += -L/home/nachtz/dpdk-2.2.0/x86_64-native-linuxapp-gcc/lib -ldpdk -lrt -lm -lgcc_s -ldl 就行了。","tags":[{"name":"DPDK","slug":"DPDK","permalink":"https://nachtz.github.io/tags/DPDK/"}]},{"title":"个人简历","date":"2016-06-17T03:19:02.000Z","path":"2016/06/17/resume/","text":"如果您有意向，请联系邮箱索要正式简历和其他信息。个人信息 男/1993 研究生/北京邮电大学 软件工程学院 可信分布式计算与服务教育部重点实验室 本科/北京邮电大学 计算机科学与技术学院 信息安全专业 期望职位：C/C++后台开发， Golang 后台开发 联系方式：nachtz@outlook.com 项目经历 国家科技支撑项目 &#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8194;C/Linux/涉密科研项目 系统能够捕获攻击流量并保存为样本，且能够利用保存的攻击流量样本生成攻击流量。在本系统中负责底层收发包接口，以及录制流量样本的功能的开发。 底层收发包平台基于DPDK实现，采用无锁Ring环将底层与API分离，使底层支持10Gbps流量的收发。 攻击流量样本捕获基于Snort实现，通过改造snort使其支持数据库配置以及输出攻击流量相关信息的功能，并添加基于TCP/UDP的攻击流缓存功能。 支持录制样本为pcap格式，写样本功能参照pcap格式手动实现，同时利用多线程分阶段并行处理报文提升录制性能。将写入样本性能从单线程最多80Mbps提升至多线程最高1000Mbps。 国家242信息安全计划&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;C/Linux/涉密科研项目 系统利用采集到的现网流量进行特征分析，依照所得到的特征进行高精度流量仿真。旨在模拟现网流量中背景流量的波动特性。 底层流量采集和发送功能基于DPDK实现，利用网卡的多队列功能，并发完成任务。 发送功能依据日志中记录的流量参数（三四层协议分布，五元组，包长分布，错包比例等）手动构造数据包并发送。最高能够支持8Gbps的流量的收发。 用户行为模拟系统 &#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195;&#8195; C++/Linux/CNCERT合作项目 系统基于配置好的行为序列生成用户流量，支持多种协议的真实用户流量的模拟以及并发操作。在本系统中负责后期维护和Debug。 系统于2016年12月验收，本人于10月被临时要求加入项目。加入时系统无法正常运行，多线程时数据库交互存在问题，并且不支持多线程并发，存在严重多线程不安全问题和其他严重bug。 通过利用C11 thread local关键字解决多线程时数据库断开连接问题。通过调用线程安全的API解决线程不安全问题，并解决了其他诸多问题。使系统成功通过验收。 实习经历 2016年11月-2016年12月 搜狗弹性云平台实习 学习了Docker及K8S的相关操作即dockerfile的编写，为云平台一期开发搭建了Jenkins平台，并编写自动编译脚本配合打通CI流程。 负责将测试部门部分服务迁移至Docker容器内部并通过测试。通过编写shell脚本和Dockerfile，在Docker镜像中自动安装服务依赖和服务配置，并加载服务通过测试，完成从编译中心到交付测试的过程。最终完成三个无状态服务的迁移以及一个基本测试数据库镜像的制作。 获奖经历 北京邮电大学2016年研究生国家奖学金 技能清单 开发语言：C, Golang, C++ 开源工具：DPDK, Docker, k8s 数据库相关：MySQL 操作系统：Linux, Windows 测试仪表：Spirent TestCenter, Spirent Avalanche 语言：英语 CET6","tags":[{"name":"Resume","slug":"Resume","permalink":"https://nachtz.github.io/tags/Resume/"}]}]